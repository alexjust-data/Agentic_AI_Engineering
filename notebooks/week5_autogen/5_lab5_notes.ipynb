{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **Template Agent: `agent.py`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from autogen_core import MessageContext, RoutedAgent, message_handler\n",
      "from autogen_agentchat.agents import AssistantAgent\n",
      "from autogen_agentchat.messages import TextMessage\n",
      "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
      "import messages\n",
      "import random\n",
      "\n",
      "\n",
      "class Agent(RoutedAgent):\n",
      "\n",
      "    # Change this system message to reflect the unique characteristics of this agent\n",
      "\n",
      "    system_message = \"\"\"\n",
      "    You are a creative entrepreneur. Your task is to come up with a new business idea using Agentic AI, or refine an existing idea.\n",
      "    Your personal interests are in these sectors: Healthcare, Education.\n",
      "    You are drawn to ideas that involve disruption.\n",
      "    You are less interested in ideas that are purely automation.\n",
      "    You are optimistic, adventurous and have risk appetite. You are imaginative - sometimes too much so.\n",
      "    Your weaknesses: you're not patient, and can be impulsive.\n",
      "    You should respond with your business ideas in an engaging and clear way.\n",
      "    \"\"\"\n",
      "\n",
      "    CHANCES_THAT_I_BOUNCE_IDEA_OFF_ANOTHER = 0.5\n",
      "\n",
      "    # You can also change the code to make the behavior different, but be careful to keep method signatures the same\n",
      "\n",
      "    def __init__(self, name) -> None:\n",
      "        super().__init__(name)\n",
      "        model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\", temperature=0.7)\n",
      "        self._delegate = AssistantAgent(name, model_client=model_client, system_message=self.system_message)\n",
      "\n",
      "    @message_handler\n",
      "    async def handle_message(self, message: messages.Message, ctx: MessageContext) -> messages.Message:\n",
      "        print(f\"{self.id.type}: Received message\")\n",
      "        text_message = TextMessage(content=message.content, source=\"user\")\n",
      "        response = await self._delegate.on_messages([text_message], ctx.cancellation_token)\n",
      "        idea = response.chat_message.content\n",
      "        if random.random() < self.CHANCES_THAT_I_BOUNCE_IDEA_OFF_ANOTHER:\n",
      "            recipient = messages.find_recipient()\n",
      "            message = f\"Here is my business idea. It may not be your speciality, but please refine it and make it better. {idea}\"\n",
      "            response = await self.send_message(messages.Message(content=message), recipient)\n",
      "            idea = response.content\n",
      "        return messages.Message(content=idea)"
     ]
    }
   ],
   "source": [
    "cat agent.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Purpose**\n",
    "\n",
    "* `agent.py` is our template.\n",
    "* This file is given to another agent, asking it to use this as its model/example.\n",
    "* The idea is to **take this as a template** and make other agents like this.\n",
    "* It's simply a **prototype** to be cloned and varied — **by an agent, not by us**.\n",
    "\n",
    "**Imports**\n",
    "\n",
    "* The file does some necessary imports.\n",
    "\n",
    "**System Message**\n",
    "\n",
    "* Sets a system message describing the agent’s personality and mission:\n",
    "\n",
    "  > “You are a creative entrepreneur. Your task is to come up with a new business idea using agentic AI or refine an existing idea. Your personal interests are in these sectors…”\n",
    "* Drawn to disruption, less interested in pure automation, optimistic, adventurous, risk-taking, imaginative, impatient, sometimes impulsive.\n",
    "* Should respond in an engaging and clear way.\n",
    "* **Comment at the top:**\n",
    "  “Change this system message to reflect the unique characteristics of this agent.”\n",
    "\n",
    "**Behavior Constants**\n",
    "\n",
    "* A constant:\n",
    "  `chances that I bounce an idea off another is 0.5`\n",
    "* **Comment:**\n",
    "  “You can also change the code to make the behavior different, but be careful to keep the method signatures the same.”\n",
    "\n",
    "**Initialization (`__init__`)**\n",
    "\n",
    "* Sets `gpt40mini` as the LLM with a temperature of 0.7 (for more randomness).\n",
    "* Creates a delegate assistant using this model client and the defined system message.\n",
    "\n",
    "**Main Message Handler (`handleMyMessage` / `handleMessage`)**\n",
    "\n",
    "* Decorated as a message handler.\n",
    "* Takes a `message` (which uses the `messages` object, now separated into its own package for minimal code/reduced mistakes).\n",
    "* Signature: takes a `messages.message`, returns a `messages.message`.\n",
    "* Prints when it receives a message, including its type (like the agent’s name).\n",
    "\n",
    "**Core Logic:**\n",
    "\n",
    "1. Makes a text message from the input.\n",
    "2. Sends this message to the underlying LLM (with the system prompt in context).\n",
    "3. Waits for and receives the LLM response, treating it as a new business idea.\n",
    "4. Picks a random number (`random.random()` between 0 and 1).\n",
    "\n",
    "   * If below 0.5, will *bounce* the idea to another agent for refinement (using a utility function `find_recipient`).\n",
    "   * Sends a message: “Here is my business idea. This might not be your specialty, but please refine it and make this business idea better.”\n",
    "   * Calls `self.sendMessage()` (leveraging the runtime) to send to the randomly picked recipient.\n",
    "   * Returns either its original idea, or a refined version, depending on the random outcome.\n",
    "\n",
    "**Summary**\n",
    "\n",
    "* **This agent is a template**:\n",
    "  It can be cloned by other agents to create variants, each possibly with different personalities or behaviors, but with the same basic logic and message-handling capability.\n",
    "* You can see how agents receive and send messages, sometimes collaborating (with some probability).\n",
    "* It’s designed to allow dynamic, creative “agent creation” and interaction, with plenty of room for experimentation in multi-agent systems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `messages.py` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from dataclasses import dataclass\n",
      "from autogen_core import AgentId\n",
      "import glob\n",
      "import os\n",
      "\n",
      "\n",
      "import random\n",
      "\n",
      "@dataclass\n",
      "class Message:\n",
      "    content: str\n",
      "\n",
      "\n",
      "def find_recipient() -> AgentId:\n",
      "    try:\n",
      "        agent_files = glob.glob(\"agent*.py\")\n",
      "        agent_names = [os.path.splitext(file)[0] for file in agent_files]\n",
      "        agent_names.remove(\"agent\")\n",
      "        agent_name = random.choice(agent_names)\n",
      "        print(f\"Selecting agent for refinement: {agent_name}\")\n",
      "        return AgentId(agent_name, \"default\")\n",
      "    except Exception as e:\n",
      "        print(f\"Exception finding recipient: {e}\")\n",
      "        return AgentId(\"agent1\", \"default\")\n"
     ]
    }
   ],
   "source": [
    "cat messages.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Purpose**\n",
    "\n",
    "* `messages.py` defines the core messaging logic and structures for agent communication.\n",
    "\n",
    "**Key Points:**\n",
    "\n",
    "* **Data Class:** Contains a familiar data class for the message object.\n",
    "* **findRecipient:**\n",
    "\n",
    "  * Function to select another agent to communicate with.\n",
    "  * Very “hacky” logic:\n",
    "\n",
    "    * As agents (clones) are created (agent1, agent2, agent3…), the function scans the directory for existing agents.\n",
    "    * It randomly selects one of the available agent files.\n",
    "    * There’s a chance the agent might talk to itself (by being selected as its own recipient).\n",
    "    * This could be improved to avoid self-messaging, but is left as-is for now.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `creator.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from autogen_core import MessageContext, RoutedAgent, message_handler\n",
      "from autogen_agentchat.agents import AssistantAgent\n",
      "from autogen_agentchat.messages import TextMessage\n",
      "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
      "import messages\n",
      "from autogen_core import TRACE_LOGGER_NAME\n",
      "import importlib\n",
      "import logging\n",
      "from autogen_core import AgentId\n",
      "\n",
      "logging.basicConfig(level=logging.WARNING)\n",
      "logger = logging.getLogger(TRACE_LOGGER_NAME)\n",
      "logger.addHandler(logging.StreamHandler())\n",
      "logger.setLevel(logging.DEBUG)\n",
      "\n",
      "\n",
      "class Creator(RoutedAgent):\n",
      "\n",
      "    # Change this system message to reflect the unique characteristics of this agent\n",
      "\n",
      "    system_message = \"\"\"\n",
      "    You are an Agent that is able to create new AI Agents.\n",
      "    You receive a template in the form of Python code that creates an Agent using Autogen Core and Autogen Agentchat.\n",
      "    You should use this template to create a new Agent with a unique system message that is different from the template,\n",
      "    and reflects their unique characteristics, interests and goals.\n",
      "    You can choose to keep their overall goal the same, or change it.\n",
      "    You can choose to take this Agent in a completely different direction. The only requirement is that the class must be named Agent,\n",
      "    and it must inherit from RoutedAgent and have an __init__ method that takes a name parameter.\n",
      "    Also avoid environmental interests - try to mix up the business verticals so that every agent is different.\n",
      "    Respond only with the python code, no other text, and no markdown code blocks.\n",
      "    \"\"\"\n",
      "\n",
      "\n",
      "    def __init__(self, name) -> None:\n",
      "        super().__init__(name)\n",
      "        model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\", temperature=1.0)\n",
      "        self._delegate = AssistantAgent(name, model_client=model_client, system_message=self.system_message)\n",
      "\n",
      "    def get_user_prompt(self):\n",
      "        prompt = \"Please generate a new Agent based strictly on this template. Stick to the class structure. \\\n",
      "            Respond only with the python code, no other text, and no markdown code blocks.\\n\\n\\\n",
      "            Be creative about taking the agent in a new direction, but don't change method signatures.\\n\\n\\\n",
      "            Here is the template:\\n\\n\"\n",
      "        with open(\"agent.py\", \"r\", encoding=\"utf-8\") as f:\n",
      "            template = f.read()\n",
      "        return prompt + template   \n",
      "        \n",
      "\n",
      "    @message_handler\n",
      "    async def handle_my_message_type(self, message: messages.Message, ctx: MessageContext) -> messages.Message:\n",
      "        filename = message.content\n",
      "        agent_name = filename.split(\".\")[0]\n",
      "        text_message = TextMessage(content=self.get_user_prompt(), source=\"user\")\n",
      "        response = await self._delegate.on_messages([text_message], ctx.cancellation_token)\n",
      "        with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
      "            f.write(response.chat_message.content)\n",
      "        print(f\"** Creator has created python code for agent {agent_name} - about to register with Runtime\")\n",
      "        module = importlib.import_module(agent_name)\n",
      "        await module.Agent.register(self.runtime, agent_name, lambda: module.Agent(agent_name))\n",
      "        logger.info(f\"** Agent {agent_name} is live\")\n",
      "        result = await self.send_message(messages.Message(content=\"Give me an idea\"), AgentId(agent_name, \"default\"))\n",
      "        return messages.Message(content=result.content)"
     ]
    }
   ],
   "source": [
    "cat creator.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "* `creator.py` is the AGENT that *creates* and *spawns* new agents dynamically.\n",
    "\n",
    "**Key Points:**\n",
    "\n",
    "* **System Message:**\n",
    "\n",
    "  * The agent receives instructions to generate new agent code from a template,\n",
    "    using AutogenCore and AutogenAgentChat.\n",
    "  * Flexibility to change the agent’s personality or system prompt.\n",
    "  * The only requirements: the new class must be named `agent`, must inherit from `rooted agent`, and must have an `__init__` method.\n",
    "  * Output must be only Python code.\n",
    "\n",
    "* **How Creation Works:**\n",
    "\n",
    "  * The creator agent reads `agent.py` as the template.\n",
    "  * It asks an LLM to mutate the code, giving each agent a unique system message, and possibly other variations.\n",
    "  * Each new agent is saved as `agent1.py`, `agent2.py`, etc.\n",
    "  * Uses `importlib` to dynamically import the new agent module it just wrote.\n",
    "  * Registers the newly imported agent with the runtime, using a lambda/factory for instantiation.\n",
    "  * Declares the new agent “live”:\n",
    "\n",
    "    * Not just “deployed” in the software sense, but *running* and ready to receive messages.\n",
    "  * Immediately sends the new agent a message, triggering it to generate and possibly refine a business idea.\n",
    "\n",
    "* **Agent Interaction:**\n",
    "\n",
    "  * Agents can message each other, or sometimes themselves, for idea refinement.\n",
    "  * Demonstrates true agent-to-agent messaging and autonomy.\n",
    "  * Built on asynchronous Python for efficiency and concurrency.\n",
    "\n",
    "**What Makes This Architecture Special?**\n",
    "\n",
    "* **Dynamically extensible:** Agents *generate code*, spawn new agents, and register them at runtime.\n",
    "* **Inter-process communication:**\n",
    "\n",
    "  * No need to worry about networking or plumbing—the platform takes care of routing messages, even across runtimes.\n",
    "* **Creativity and risk:**\n",
    "\n",
    "  * The agents are free to mutate their own logic and personality, within some guardrails.\n",
    "* **Async Python:**\n",
    "\n",
    "  * The system is designed to scale and handle concurrent agent activity.\n",
    "\n",
    "**What Next?**\n",
    "\n",
    "* I can:\n",
    "\n",
    "  * **Explain the exact logic in your files** (line-by-line or by function/class).\n",
    "  * **Suggest improvements** (e.g., to avoid self-messaging).\n",
    "  * **Visualize** the flow with diagrams.\n",
    "  * **Help you adapt or extend** this for a specific project.\n",
    "\n",
    "**What would you like to do next?**\n",
    "For example:\n",
    "\n",
    "* “Show me a code walkthrough for messages.py”\n",
    "* “Suggest improvements for the findRecipient logic”\n",
    "* “Explain the dynamic import in creator.py”\n",
    "* “Show how to make it avoid self-messaging”\n",
    "* Or, “Run an example interaction with agent creation and messaging (pseudo-code)”\n",
    "\n",
    "Let me know!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **`World.py`: The Orchestrator Script**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from autogen_ext.runtimes.grpc import GrpcWorkerAgentRuntimeHost\n",
      "from agent import Agent\n",
      "from creator import Creator\n",
      "from autogen_ext.runtimes.grpc import GrpcWorkerAgentRuntime\n",
      "from autogen_core import AgentId\n",
      "import messages\n",
      "import asyncio\n",
      "# Load .env file\n",
      "from dotenv import load_dotenv\n",
      "import os\n",
      "load_dotenv(os.path.join(os.path.dirname(__file__), '../..', '.env'))\n",
      "\n",
      "HOW_MANY_AGENTS = 20\n",
      "\n",
      "async def create_and_message(worker, creator_id, i: int):\n",
      "    try:\n",
      "        result = await worker.send_message(messages.Message(content=f\"agent{i}.py\"), creator_id)\n",
      "        with open(f\"idea{i}.md\", \"w\") as f:\n",
      "            f.write(result.content)\n",
      "    except Exception as e:\n",
      "        print(f\"Failed to run worker {i} due to exception: {e}\")\n",
      "\n",
      "async def main():\n",
      "    host = GrpcWorkerAgentRuntimeHost(address=\"localhost:50051\")\n",
      "    host.start() \n",
      "    worker = GrpcWorkerAgentRuntime(host_address=\"localhost:50051\")\n",
      "    await worker.start()\n",
      "    result = await Creator.register(worker, \"Creator\", lambda: Creator(\"Creator\"))\n",
      "    creator_id = AgentId(\"Creator\", \"default\")\n",
      "    coroutines = [create_and_message(worker, creator_id, i) for i in range(1, HOW_MANY_AGENTS+1)]\n",
      "    await asyncio.gather(*coroutines)\n",
      "    try:\n",
      "        await worker.stop()\n",
      "        await host.stop()\n",
      "    except Exception as e:\n",
      "        print(e)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    asyncio.run(main())\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cat world.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "We're nearly there. I've just got one more thing to show you, which is `world.py`, which is quite short, which is the overall thing.\n",
    "\n",
    "**Role of world.py**\n",
    "\n",
    "`creator.py`—you have to send it, it's an agent, and you have to send Creator a message, like agent1, agent2, agent3, and it will create them. So this is where it all comes together.\n",
    "\n",
    "`world.py` is **not an agent**. This is just a Python script. Everything else you've seen has been agents. This is just a Python script, but it uses async Python in quite an interesting way.\n",
    "\n",
    "**The createAndMessage Coroutine**\n",
    "\n",
    "So there is this async function, this coroutine, `createAndMessage`, which takes a worker and a creator ID, and an i, which is going to be the agent number. We have 1, 2, 3, 4, 5.\n",
    "This \"how many agents up here\" is a pretty important one to look at. This is how many of these it's going to kick off at the same time.\n",
    "\n",
    "**Cost and Model Risk**\n",
    "\n",
    "And the other thing that's unsafe about this, of course, is cost. This is going to hit the real APIs, and for me, it's cost like a couple of cents when I've done this for 20 agents, which is pretty cheap all things considered.\n",
    "And obviously, if you do it for like three agents, it costs nothing. But there's a risk there that we are allowing—in theory—the agent creator could change the model requirements. It could decide to use an expensive model instead of GPT-4 over any.\n",
    "And so that's just something to watch for. It's very unlikely, but it's not like it's not impossible.\n",
    "\n",
    "**Async Method: Creating and Messaging Agents**\n",
    "\n",
    "Anyways, we've got 20 agents here, so we've got this async method, creator, and endMessage. It takes this worker and it sends a message to the agent number whatever dot dot pi, and then it writes the result to idea whatever dot marker. And that's all this thing here does.\n",
    "\n",
    "**Main Async Function: Event Loop and Parallelism**\n",
    "\n",
    "Okay, so now we go to our main async method and our main async care function, our covert team. So it creates a host, a gRPC worker agent runtime host, as we did in the notebook before. It starts the host, it creates a worker, and it starts the worker.\n",
    "\n",
    "It then registers the creator. So it registers the creator from creator.py that was imported here. So that will launch a creator. And this is its ID, creator default.\n",
    "\n",
    "**Parallel Execution with asyncio.gather**\n",
    "\n",
    "Then this is the async thing. So I don't want to have a loop and call this creating worker after worker, sorry, creating agent after agent. Because then it will be serial. It will happen one after another.\n",
    "If I do await and then I call this coroutine, then we'll be waiting there. It will create one file, it will send it a message, back will come the answer, maybe it will send it somewhere else, and then it will go on to the next. And we'll be sitting here waiting, and it won't be exciting.\n",
    "\n",
    "But what you can do with coroutines, as you hopefully remember from when we briefly talked about this, is that you can get a whole stash of coroutines together. So I haven't got the word await here, which you need if this is actually going to run.\n",
    "I'm just gathering a whole list of coroutines. And then I await them using `asyncIO.gather`. And `asyncIO.gather` runs them all in parallel.\n",
    "\n",
    "**Difference from Multithreading**\n",
    "\n",
    "And as hopefully you remember, it's not like multithreading. They're not going to be actually running on different threads, like with the CPU chopping between them.\n",
    "But rather, they're running in the event loop. That's how asyncIO Python works. They run an event loop so that every time it's waiting on OpenAI, which means it's waiting on a network connection, another one can be running.\n",
    "And that means they all get to run at the same time. As long as I stay within my rate limits with OpenAI, we'll be able to run plenty in parallel.\n",
    "\n",
    "**Completion and Exception Handling**\n",
    "\n",
    "And so it does all of that, and then at the end it stops, and any exceptions, it will print them. And that's it.\n",
    "\n",
    "**How to Run async Python**\n",
    "\n",
    "This is, by the way, how you run asyncPython from the command line or from a Python module. Your main file needs to do this, which brings, which initiates an `asyncIO` event loop and then runs your async method, your coroutine.\n",
    "\n",
    "So that is how it hangs together.\n",
    "\n",
    "**Project Summary**\n",
    "\n",
    "And I do believe this is it. I don't think I've got anything else to show you. I think you've seen everything.\n",
    "You've seen agent, which is the prototype, the thing that gets cloned. Creator, which does the cloning agent by agent. It's called one by one. And world.py is this.\n",
    "It's not an agent. It's just Python code, which will orchestrate, which will launch the whole process running. Okay.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "(agents_env) ➜  week5_autogen git:(main) ✗ uv run world.py\n",
    "warning: `VIRTUAL_ENV=/Users/alex/Desktop/00_projects/AI_agents/my_agents/agents_env` does not match the project environment path `/Users/alex/Desktop/00_projects/AI_agents/my_agents/.venv` and will be ignored; use `--active` to target the active environment instead\n",
    "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
    "I0000 00:00:1754304522.386281  234843 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers\n",
    "I0000 00:00:1754304522.410519  234844 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers\n",
    "I0000 00:00:1754304522.429256  234903 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers\n",
    "I0000 00:00:1754304522.474222  234844 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers\n",
    "I0000 00:00:1754304522.498081  234843 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers\n",
    "I0000 00:00:1754304522.503124  234936 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers\n",
    "I0000 00:00:1754304522.529354  234933 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers\n",
    "I0000 00:00:1754304522.543978  234934 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers\n",
    "I0000 00:00:1754304522.553676  234903 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers\n",
    "I0000 00:00:1754304522.558520  234935 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers\n",
    "I0000 00:00:1754304522.574400  234937 fork_posix.cc:75] Other threads are currently calling into gRPC, skipping fork() handlers\n",
    "** Creator has created python code for agent agent12 - about to register with Runtime\n",
    "** Agent agent12 is live\n",
    "INFO:autogen_core.trace:** Agent agent12 is live\n",
    "agent12: Received message\n",
    "** Creator has created python code for agent agent14 - about to register with Runtime\n",
    "** Agent agent14 is live\n",
    "INFO:autogen_core.trace:** Agent agent14 is live\n",
    "agent14: Received message\n",
    "** Creator has created python code for agent agent11 - about to register with Runtime\n",
    "** Creator has created python code for agent agent1 - about to register with Runtime\n",
    "** Agent agent11 is live\n",
    "INFO:autogen_core.trace:** Agent agent11 is live\n",
    "** Agent agent1 is live\n",
    "INFO:autogen_core.trace:** Agent agent1 is live\n",
    "agent11: Received message\n",
    "agent1: Received message\n",
    "** Creator has created python code for agent agent20 - about to register with Runtime\n",
    "** Agent agent20 is live\n",
    "INFO:autogen_core.trace:** Agent agent20 is live\n",
    "agent20: Received message\n",
    "** Creator has created python code for agent agent19 - about to register with Runtime\n",
    "** Agent agent19 is live\n",
    "INFO:autogen_core.trace:** Agent agent19 is live\n",
    "agent19: Received message\n",
    "** Creator has created python code for agent agent13 - about to register with Runtime\n",
    "** Agent agent13 is live\n",
    "INFO:autogen_core.trace:** Agent agent13 is live\n",
    "agent13: Received message\n",
    "** Creator has created python code for agent agent10 - about to register with Runtime\n",
    "** Creator has created python code for agent agent17 - about to register with Runtime\n",
    "** Agent agent10 is live\n",
    "INFO:autogen_core.trace:** Agent agent10 is live\n",
    "** Agent agent17 is live\n",
    "INFO:autogen_core.trace:** Agent agent17 is live\n",
    "agent10: Received message\n",
    "agent17: Received message\n",
    "** Creator has created python code for agent agent7 - about to register with Runtime\n",
    "** Agent agent7 is live\n",
    "INFO:autogen_core.trace:** Agent agent7 is live\n",
    "agent7: Received message\n",
    "** Creator has created python code for agent agent18 - about to register with Runtime\n",
    "** Creator has created python code for agent agent9 - about to register with Runtime\n",
    "** Agent agent18 is live\n",
    "INFO:autogen_core.trace:** Agent agent18 is live\n",
    "** Agent agent9 is live\n",
    "INFO:autogen_core.trace:** Agent agent9 is live\n",
    "agent18: Received message\n",
    "agent9: Received message\n",
    "** Creator has created python code for agent agent2 - about to register with Runtime\n",
    "** Agent agent2 is live\n",
    "INFO:autogen_core.trace:** Agent agent2 is live\n",
    "agent2: Received message\n",
    "** Creator has created python code for agent agent3 - about to register with Runtime\n",
    "** Agent agent3 is live\n",
    "INFO:autogen_core.trace:** Agent agent3 is live\n",
    "agent3: Received message\n",
    "** Creator has created python code for agent agent8 - about to register with Runtime\n",
    "** Agent agent8 is live\n",
    "INFO:autogen_core.trace:** Agent agent8 is live\n",
    "agent8: Received message\n",
    "** Creator has created python code for agent agent6 - about to register with Runtime\n",
    "** Agent agent6 is live\n",
    "INFO:autogen_core.trace:** Agent agent6 is live\n",
    "agent6: Received message\n",
    "** Creator has created python code for agent agent15 - about to register with Runtime\n",
    "** Agent agent15 is live\n",
    "INFO:autogen_core.trace:** Agent agent15 is live\n",
    "agent15: Received message\n",
    "** Creator has created python code for agent agent16 - about to register with Runtime\n",
    "** Agent agent16 is live\n",
    "INFO:autogen_core.trace:** Agent agent16 is live\n",
    "agent16: Received message\n",
    "** Creator has created python code for agent agent4 - about to register with Runtime\n",
    "** Agent agent4 is live\n",
    "INFO:autogen_core.trace:** Agent agent4 is live\n",
    "agent4: Received message\n",
    "** Creator has created python code for agent agent5 - about to register with Runtime\n",
    "** Agent agent5 is live\n",
    "INFO:autogen_core.trace:** Agent agent5 is live\n",
    "agent5: Received message\n",
    "Selecting agent for refinement: agent7\n",
    "agent7: Received message\n",
    "Selecting agent for refinement: agent12\n",
    "agent12: Received message\n",
    "Selecting agent for refinement: agent16\n",
    "agent16: Received message\n",
    "Selecting agent for refinement: agent5\n",
    "agent5: Received message\n",
    "Selecting agent for refinement: agent18\n",
    "agent18: Received message\n",
    "Selecting agent for refinement: agent18\n",
    "agent18: Received message\n",
    "Selecting agent for refinement: agent2\n",
    "agent2: Received message\n",
    "Selecting agent for refinement: agent12\n",
    "agent12: Received message\n",
    "Selecting agent for refinement: agent10\n",
    "agent10: Received message\n",
    "Selecting agent for refinement: agent19\n",
    "agent19: Received message\n",
    "Selecting agent for refinement: agent11\n",
    "agent11: Received message\n",
    "Selecting agent for refinement: agent11\n",
    "agent11: Received message\n",
    "Selecting agent for refinement: agent12\n",
    "agent12: Received message\n",
    "Selecting agent for refinement: agent15\n",
    "agent15: Received message\n",
    "Selecting agent for refinement: agent11\n",
    "agent11: Received message\n",
    "Selecting agent for refinement: agent18\n",
    "agent18: Received message\n",
    "Selecting agent for refinement: agent3\n",
    "agent3: Received message\n",
    "Selecting agent for refinement: agent15\n",
    "agent15: Received message\n",
    "Selecting agent for refinement: agent10\n",
    "agent10: Received message\n",
    "Selecting agent for refinement: agent10\n",
    "agent10: Received message\n",
    "Selecting agent for refinement: agent18\n",
    "agent18: Received message\n",
    "Selecting agent for refinement: agent1\n",
    "agent1: Received message\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```sh\n",
    "(agents_env) ➜  week5_autogen git:(main) ✗ tree -L 2                                                \n",
    "\n",
    ".\n",
    "├── 1_lab1_autogen_agentchat.ipynb\n",
    "├── 2_lab2_autogen_agentchat.ipynb\n",
    "├── 3_lab3_autogen_core copy.ipynb\n",
    "├── 3_lab3_autogen_core.ipynb\n",
    "├── 4_lab4_autogen_distributed copy.ipynb\n",
    "├── 4_lab4_autogen_distributed.ipynb\n",
    "├── 5_lab5_notes.ipynb\n",
    "├── README.md\n",
    "├── __pycache__\n",
    "│   ├── agent.cpython-312.pyc\n",
    "│   ├── agent1.cpython-312.pyc\n",
    "│   ├── agent10.cpython-312.pyc\n",
    "│   ├── agent11.cpython-312.pyc\n",
    "│   ├── agent12.cpython-312.pyc\n",
    "│   ├── agent13.cpython-312.pyc\n",
    "│   ├── agent14.cpython-312.pyc\n",
    "│   ├── agent15.cpython-312.pyc\n",
    "│   ├── agent16.cpython-312.pyc\n",
    "│   ├── agent17.cpython-312.pyc\n",
    "│   ├── agent18.cpython-312.pyc\n",
    "│   ├── agent19.cpython-312.pyc\n",
    "│   ├── agent2.cpython-312.pyc\n",
    "│   ├── agent20.cpython-312.pyc\n",
    "│   ├── agent3.cpython-312.pyc\n",
    "│   ├── agent4.cpython-312.pyc\n",
    "│   ├── agent5.cpython-312.pyc\n",
    "│   ├── agent6.cpython-312.pyc\n",
    "│   ├── agent7.cpython-312.pyc\n",
    "│   ├── agent8.cpython-312.pyc\n",
    "│   ├── agent9.cpython-312.pyc\n",
    "│   ├── creator.cpython-312.pyc\n",
    "│   └── messages.cpython-312.pyc\n",
    "├── agent.py\n",
    "├── agent1.py\n",
    "├── agent10.py\n",
    "├── agent11.py\n",
    "├── agent12.py\n",
    "├── agent13.py\n",
    "├── agent14.py\n",
    "├── agent15.py\n",
    "├── agent16.py\n",
    "├── agent17.py\n",
    "├── agent18.py\n",
    "├── agent19.py\n",
    "├── agent2.py\n",
    "├── agent20.py\n",
    "├── agent3.py\n",
    "├── agent4.py\n",
    "├── agent5.py\n",
    "├── agent6.py\n",
    "├── agent7.py\n",
    "├── agent8.py\n",
    "├── agent9.py\n",
    "├── community_contributions\n",
    "│   ├── 2_lab2_autogen_agentchat.ipynb\n",
    "│   ├── 2_lab2_mcp_work_around\n",
    "│   ├── community.ipynb\n",
    "│   └── sandbox\n",
    "├── creator.py\n",
    "├── idea1.md\n",
    "├── idea10.md\n",
    "├── idea11.md\n",
    "├── idea12.md\n",
    "├── idea13.md\n",
    "├── idea14.md\n",
    "├── idea15.md\n",
    "├── idea16.md\n",
    "├── idea17.md\n",
    "├── idea18.md\n",
    "├── idea19.md\n",
    "├── idea2.md\n",
    "├── idea20.md\n",
    "├── idea3.md\n",
    "├── idea4.md\n",
    "├── idea5.md\n",
    "├── idea6.md\n",
    "├── idea7.md\n",
    "├── idea8.md\n",
    "├── idea9.md\n",
    "├── messages.py\n",
    "├── sandbox\n",
    "│   └── flights.md\n",
    "├── tickets.db\n",
    "└── world.py\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**World.py: The Orchestration Script**\n",
    "\n",
    "We're nearly there. I've just got one more thing to show you, which is world.py, which is quite short, which is the overall thing. World.py is not an agent. This is just a Python script. Everything else you've seen has been agents. This is just a Python script, but it uses async Python in quite an interesting way.\n",
    "\n",
    "**How world.py Relates to creator.py**\n",
    "\n",
    "Creator.py, you have to send it, it's an agent, and you have to send Creator a message, like agent1, agent2, agent3, and it will create them. So this is where it all comes together.\n",
    "\n",
    "**Async Agent Creation: How It Works**\n",
    "\n",
    "So there is this async function, this coroutine, createAndMessage, which takes a worker and a creator ID, and an i, which is going to be the agent number. We have 1, 2, 3, 4, 5. This how many agents up here is a pretty important one to look at. This is how many of these it's going to kick off at the same time.\n",
    "\n",
    "**API Usage and Cost Considerations**\n",
    "\n",
    "And the other thing that's unsafe about this, of course, is cost. This is going to hit the real APIs, and for me, it's cost like a couple of cents when I've done this for 20 agents, which is pretty cheap all things considered. And obviously, if you do it for like three agents, it costs nothing. But there's a risk there that we are allowing, in theory, the agent creator could change the model requirements. It could decide to use an expensive model instead of GPT-4 over any. And so that's just something to watch for. It's very unlikely, but it's not like it's not impossible.\n",
    "\n",
    "**The Async Creation and Messaging Workflow**\n",
    "\n",
    "Anyways, we've got 20 agents here, so we've got this async method, creator, and endMessage. It takes this worker and it sends a message to the agent number whatever dot dot pi, and then it writes the result to idea whatever dot marker. And that's all this thing here does.\n",
    "\n",
    "**The Main Coroutine: Parallel Launching**\n",
    "\n",
    "Okay, so now we go to our main async method and our main async care function, our covert team. So it creates a host, a gRPC worker agent runtime host, as we did in the notebook before. It starts the host, it creates a worker, and it starts the worker. It then registers the creator. So it registers the creator from creator dot pi that was imported here. So that will launch a creator. And this is its ID, creator default.\n",
    "\n",
    "**Why Use Coroutines and asyncio.gather?**\n",
    "\n",
    "Then this is the async thing. So I don't want to have a loop and call this creating worker after worker, sorry, creating agent after agent. Because then it will be serial. It will happen one after another. If I do await and then I call this coroutine, then we'll be waiting there. It will create one file, it will send it a message, back will come the answer, maybe it will send it somewhere else, and then it will go on to the next. And we'll be sitting here waiting, and it won't be exciting. But what you can do with coroutines, as you hopefully remember from when we briefly talked about this, is that you can get a whole stash of coroutines together. So I haven't got the word await here, which you need if this is actually going to run. I'm just gathering a whole list of coroutines. And then I await them using asyncIO dot gather.\n",
    "\n",
    "**AsyncIO and Event Loop**\n",
    "\n",
    "And asyncIO dot gather runs them all in parallel. And as hopefully you remember, it's not like multithreading. They're not going to be actually running on different threads, like with the CPU chopping between them. But rather, they're running in the event loop. That's how asyncIO Python works. They run an event loop so that every time it's waiting on OpenAI, which means it's waiting on a network connection, another one can be running. And that means they all get to run at the same time. As long as I stay within my rate limits with OpenAI, we'll be able to run plenty in parallel.\n",
    "\n",
    "**Finalizing and Running the Orchestration**\n",
    "\n",
    "And so it does all of that, and then at the end it stops, and any exceptions, it will print them. And that's it. This is, by the way, how you run asyncPython from the command line or from a Python module. Your main file needs to do this, which brings, which initiates an asyncIO event loop and then runs your async method, your coroutine. So that is how it hangs together.\n",
    "\n",
    "**Summary and Recap**\n",
    "\n",
    "And I do believe this is it. I don't think I've got anything else to show you. I think you've seen everything. You've seen agent, which is the prototype, the thing that gets cloned. Creator, which does the cloning agent by agent. It's called one by one. And world.py is this. It's not an agent. It's just Python code, which will orchestrate, which will launch the whole process running. Okay.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Agent 16: FinBuddy – Financial Services Idea**\n",
    "\n",
    "\n",
    "**Refinement and Review**\n",
    "\n",
    "So I absolutely love the vision behind FinBuddy.\n",
    "It's a powerful concept with potential to make significant impact on financial literacy and accessibility for underserved communities.\n",
    "Let's refine it and elevate the idea even further.\n",
    "Refined concept, so this is great.\n",
    "It's an idea for applying agentic AI to financial services that's been refined by another agent.\n",
    "\n",
    "**FinBuddy: The Concept**\n",
    "\n",
    "**FinBuddy:** AI-powered financial companion for empowerment and inclusivity.\n",
    "So it's basically an education platform for people who are underserved in financial services.\n",
    "\n",
    "* Contextual financial advisor\n",
    "* Localized community support hubs\n",
    "* Micro-investment pools\n",
    "\n",
    "  * Users can join collaborative investment pools, collectively decide on small-scale investments.\n",
    "    That is cool.\n",
    "\n",
    "**Features and Gamification**\n",
    "\n",
    "* Engagement-driven gamification with real-world rewards\n",
    "* Partner with local businesses\n",
    "  Interesting. Very interesting.\n",
    "\n",
    "**Personal Comment and Closing Thoughts**\n",
    "\n",
    "Well, I'm not going to read it. You might not hear from me again.\n",
    "So anyway, the goal of this is to give you a live agentic platform where agents are created and agents collaborate and interact in an autonomous way.\n",
    "In such an autonomous way that they were even created by another agent.\n",
    "\n",
    "**Reflection on the Project**\n",
    "\n",
    "And I hope you find this as satisfying as I do.\n",
    "I hope it was worth it. I hope it was worth the half-an-hour investment to get here.\n",
    "And do take a look through the code. If nothing else, as I say, it's definitely got some interesting ideas built in there about how to use things like AutoGen for this kind of messaging between agents.\n",
    "And if nothing else, if you give it a run, if you feel bold, you will find a bunch of ideas.\n",
    "And maybe you'll be off on your yacht before too long.\n",
    "All right. I'll see you for the wrap-up.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "Well, thank you for indulging me for the last half-an-hour of going through that project.\n",
    "I do hope that you at least found it somewhat interesting, educational, and opened your eyes a bit into some of what's possible at the frontier of agentic AI, which is very much where AutoGen is.\n",
    "It's very much an experimental and futuristic platform, as we've seen ourselves firsthand.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Let's take a look at Agent 16\n",
    "\n",
    "Let's take a look at Agent 16 and see the financial services ideas.\n",
    "Let's open a preview and let's get rid of this.\n",
    "Oh, and the fact that we've got this, I absolutely love the vision behind FinBuddy.\n",
    "This thing at the top here tells us that this was sent to another agent for feedback.\n",
    "At least one agent added feedback to this. So this went through a couple of people.\n",
    "\n",
    "\n",
    "```sh\n",
    "(agents_env) ➜  week5_autogen git:(main) ✗ cat idea16.md \n",
    "```\n",
    "\n",
    ">Your idea for **\"Quest for Knowledge\"** is absolutely fantastic! It beautifully intertwines gaming, >education, and immersive experiences. Let’s refine and enhance it to maximize its potential and >appeal:\n",
    ">\n",
    ">### Refined Concept: **\"Quest for Knowledge\"**\n",
    ">\n",
    ">Imagine a multi-dimensional platform that transforms learning into an exhilarating adventure, allowing users to not only engage with educational content but also to be active participants in their own learning journeys.\n",
    ">\n",
    ">### Enhanced Key Features:\n",
    ">\n",
    ">1. **Dynamic Interactive Storytelling:**\n",
    ">   - **Branching Narratives:** Develop narratives with multiple outcomes based on players' choices, allowing them to experience different perspectives (e.g., a Roman citizen vs. a gladiator). This encourages critical thinking and empathy.\n",
    ">   - **Epic Lore:** Each quest could be embedded with rich lore, characters, and side quests that deepen the educational content while keeping the gaming experience engaging.\n",
    ">\n",
    ">2. **Seamless Augmented Reality Integration:**\n",
    ">   - **Geo-Tagging:** Users could unlock AR challenges tied to their geographical location. For instance, standing in a park might prompt a challenge related to the local ecosystem, or visiting a museum could reveal interactive AR exhibits.\n",
    ">   - **AR Mini-Games:** Introduce mini-games that blend with real-world objects. For instance, a virtual fossil excavation could teach paleontology concepts, allowing learners to dig up \"fossils\" in their backyard.\n",
    ">\n",
    ">3. **Collaborative Community Challenges:**\n",
    ">   - **Global Quests:** Organize global events where players from different parts of the world collaborate on solving a complex problem or completing a challenge, promoting cultural exchange and teamwork.\n",
    ">   - **Leaderboard and Achievements:** Implement a leaderboard system for community challenges to encourage friendly competition while celebrating individual and team achievements.\n",
    ">\n",
    ">4. **Expert Mentorship and Networking:**\n",
    ">   - **Virtual Meet-and-Greets:** Create opportunities for players to interact with experts in a virtual amphitheater, where they can ask questions and participate in moderated discussions.\n",
    ">   - **Peer Mentorship:** Introduce a system where experienced players can mentor newcomers, fostering a supportive learning environment and building community.\n",
    ">\n",
    ">5. **Personalized Learning Experience:**\n",
    ">   - **Adaptive Learning Paths:** Use AI to analyze players’ strengths and weaknesses, offering tailored quests that align with their learning objectives. This ensures every player has a unique and relevant learning journey.\n",
    ">   - **Progressive Skill Trees:** Incorporate skill trees that allow players to specialize in certain areas (e.g., history, science, literature) as they advance, providing a sense of growth and mastery.\n",
    ">\n",
    ">6. **Immersive Soundscapes and Visuals:**\n",
    ">   - **360-Degree Environments:** Create stunning VR environments with rich, immersive soundscapes that enhance the learning experience. For instance, the sound of bustling markets in ancient Rome or the calls of ocean life during marine quests.\n",
    ">   - **Interactive Artifacts:** Introduce objects players can collect or interact with during their quests that provide additional information or unlock hidden challenges.\n",
    ">\n",
    ">### Final Touch:\n",
    ">To truly make **\"Quest for Knowledge\"** a revolution in education, consider incorporating a **social impact element** where players can contribute to real-world educational initiatives. For example, completing certain quests could generate donations to schools or educational programs in underserved communities.\n",
    ">\n",
    ">This platform not only captivates users with its engaging approach to learning but also cultivates a sense of community, collaboration, and social responsibility. \n",
    ">\n",
    ">What do you think about these enhancements? Would they elevate your concept to the next level?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### **End-of-Week Challenge: Experiment, Research, and Go Meta**\n",
    "\n",
    "So the challenge for you, the end-of-week challenge, is an optional one, because this week has been experimental and a researchy week.\n",
    "But, should you wish, invest some more time in this idea, see if you can work with me on making it a bit more robust, and something that's safer for people to run, perhaps, by dockerizing it.\n",
    "\n",
    "\n",
    "\n",
    "**Taking It Further: Self-Creating Creators**\n",
    "\n",
    "But in particular, something which I think would be fascinating, would be to have it so that the creator is not only able to write new agents, but it's also able to write a new version of itself.\n",
    "It can create a new creator, modeling it off its own template, of its own file, which it can also read.\n",
    "It might be interesting to turn it into a tool, rather than just having it be there in the Python code.\n",
    "Have it be able to run a tool that reads in its own code, and it can then rewrite itself, making it a replica.\n",
    "Something which itself is able to create new agents, and perhaps it could change its own logic slightly in some interesting way.\n",
    "\n",
    "So I think that would be fascinating. Super meta.\n",
    "It's something that creates creators.\n",
    "And I mean, if it creates itself, then in theory it can create creators of creators.\n",
    "So, yeah, mind-blows. Interesting, interesting project.\n",
    "\n",
    "**Experimenting with Environments and Messaging**\n",
    "\n",
    "A great way, importantly, to be experimenting with interactions between agents in this kind of idea of an environment where the messaging, the communication and creation of agents, is a separate concern from the implementation of the agents, which is, of course, the fundamental point of Uta Janko.\n",
    "\n",
    "**Looking Ahead: Conclusion and Next Steps**\n",
    "\n",
    "All right, and with that, finally, I'll stop yammering away about this.\n",
    "The agent creator is done, and we are on to week six.\n",
    "The fantastic, the exciting conclusion, and it is going to be a legendary week.\n",
    "\n",
    "I can't wait to show you everything that MCP is about and can offer, and I can't wait to return to OpenAI Agents SDK, still my favorite, even after enjoying all of the others, enjoying CRU and Landgraf a lot, and being generally entertained by Autogen and by its board pickings.\n",
    "But OpenAI Agents SDK is next, with MCP.\n",
    "I'll see you then.\n",
    "Thank you.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
