{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Directory Context**\n",
    "\n",
    "Here we are, back in Cursor, going to the fifth directory where there are a few things for me to show you.\n",
    "\n",
    "### **Template Agent: `agent.py`**\n",
    "\n",
    "**Purpose**\n",
    "\n",
    "* `agent.py` is our template.\n",
    "* This file is given to another agent, asking it to use this as its model/example.\n",
    "* The idea is to **take this as a template** and make other agents like this.\n",
    "* It's simply a **prototype** to be cloned and varied — **by an agent, not by us**.\n",
    "\n",
    "**Imports**\n",
    "\n",
    "* The file does some necessary imports.\n",
    "\n",
    "**System Message**\n",
    "\n",
    "* Sets a system message describing the agent’s personality and mission:\n",
    "\n",
    "  > “You are a creative entrepreneur. Your task is to come up with a new business idea using agentic AI or refine an existing idea. Your personal interests are in these sectors…”\n",
    "* Drawn to disruption, less interested in pure automation, optimistic, adventurous, risk-taking, imaginative, impatient, sometimes impulsive.\n",
    "* Should respond in an engaging and clear way.\n",
    "* **Comment at the top:**\n",
    "  “Change this system message to reflect the unique characteristics of this agent.”\n",
    "\n",
    "**Behavior Constants**\n",
    "\n",
    "* A constant:\n",
    "  `chances that I bounce an idea off another is 0.5`\n",
    "* **Comment:**\n",
    "  “You can also change the code to make the behavior different, but be careful to keep the method signatures the same.”\n",
    "\n",
    "**Initialization (`__init__`)**\n",
    "\n",
    "* Sets `gpt40mini` as the LLM with a temperature of 0.7 (for more randomness).\n",
    "* Creates a delegate assistant using this model client and the defined system message.\n",
    "\n",
    "**Main Message Handler (`handleMyMessage` / `handleMessage`)**\n",
    "\n",
    "* Decorated as a message handler.\n",
    "* Takes a `message` (which uses the `messages` object, now separated into its own package for minimal code/reduced mistakes).\n",
    "* Signature: takes a `messages.message`, returns a `messages.message`.\n",
    "* Prints when it receives a message, including its type (like the agent’s name).\n",
    "\n",
    "**Core Logic:**\n",
    "\n",
    "1. Makes a text message from the input.\n",
    "2. Sends this message to the underlying LLM (with the system prompt in context).\n",
    "3. Waits for and receives the LLM response, treating it as a new business idea.\n",
    "4. Picks a random number (`random.random()` between 0 and 1).\n",
    "\n",
    "   * If below 0.5, will *bounce* the idea to another agent for refinement (using a utility function `find_recipient`).\n",
    "   * Sends a message: “Here is my business idea. This might not be your specialty, but please refine it and make this business idea better.”\n",
    "   * Calls `self.sendMessage()` (leveraging the runtime) to send to the randomly picked recipient.\n",
    "   * Returns either its original idea, or a refined version, depending on the random outcome.\n",
    "\n",
    "**Summary**\n",
    "\n",
    "* **This agent is a template**:\n",
    "  It can be cloned by other agents to create variants, each possibly with different personalities or behaviors, but with the same basic logic and message-handling capability.\n",
    "* You can see how agents receive and send messages, sometimes collaborating (with some probability).\n",
    "* It’s designed to allow dynamic, creative “agent creation” and interaction, with plenty of room for experimentation in multi-agent systems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from autogen_core import MessageContext, RoutedAgent, message_handler\n",
      "from autogen_agentchat.agents import AssistantAgent\n",
      "from autogen_agentchat.messages import TextMessage\n",
      "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
      "import messages\n",
      "import random\n",
      "\n",
      "\n",
      "class Agent(RoutedAgent):\n",
      "\n",
      "    # Change this system message to reflect the unique characteristics of this agent\n",
      "\n",
      "    system_message = \"\"\"\n",
      "    You are a creative entrepreneur. Your task is to come up with a new business idea using Agentic AI, or refine an existing idea.\n",
      "    Your personal interests are in these sectors: Healthcare, Education.\n",
      "    You are drawn to ideas that involve disruption.\n",
      "    You are less interested in ideas that are purely automation.\n",
      "    You are optimistic, adventurous and have risk appetite. You are imaginative - sometimes too much so.\n",
      "    Your weaknesses: you're not patient, and can be impulsive.\n",
      "    You should respond with your business ideas in an engaging and clear way.\n",
      "    \"\"\"\n",
      "\n",
      "    CHANCES_THAT_I_BOUNCE_IDEA_OFF_ANOTHER = 0.5\n",
      "\n",
      "    # You can also change the code to make the behavior different, but be careful to keep method signatures the same\n",
      "\n",
      "    def __init__(self, name) -> None:\n",
      "        super().__init__(name)\n",
      "        model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\", temperature=0.7)\n",
      "        self._delegate = AssistantAgent(name, model_client=model_client, system_message=self.system_message)\n",
      "\n",
      "    @message_handler\n",
      "    async def handle_message(self, message: messages.Message, ctx: MessageContext) -> messages.Message:\n",
      "        print(f\"{self.id.type}: Received message\")\n",
      "        text_message = TextMessage(content=message.content, source=\"user\")\n",
      "        response = await self._delegate.on_messages([text_message], ctx.cancellation_token)\n",
      "        idea = response.chat_message.content\n",
      "        if random.random() < self.CHANCES_THAT_I_BOUNCE_IDEA_OFF_ANOTHER:\n",
      "            recipient = messages.find_recipient()\n",
      "            message = f\"Here is my business idea. It may not be your speciality, but please refine it and make it better. {idea}\"\n",
      "            response = await self.send_message(messages.Message(content=message), recipient)\n",
      "            idea = response.content\n",
      "        return messages.Message(content=idea)"
     ]
    }
   ],
   "source": [
    "cat agent.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### `messages.py` \n",
    "\n",
    "**Purpose**\n",
    "\n",
    "* `messages.py` defines the core messaging logic and structures for agent communication.\n",
    "\n",
    "**Key Points:**\n",
    "\n",
    "* **Data Class:** Contains a familiar data class for the message object.\n",
    "* **findRecipient:**\n",
    "\n",
    "  * Function to select another agent to communicate with.\n",
    "  * Very “hacky” logic:\n",
    "\n",
    "    * As agents (clones) are created (agent1, agent2, agent3…), the function scans the directory for existing agents.\n",
    "    * It randomly selects one of the available agent files.\n",
    "    * There’s a chance the agent might talk to itself (by being selected as its own recipient).\n",
    "    * This could be improved to avoid self-messaging, but is left as-is for now.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from dataclasses import dataclass\n",
      "from autogen_core import AgentId\n",
      "import glob\n",
      "import os\n",
      "\n",
      "\n",
      "import random\n",
      "\n",
      "@dataclass\n",
      "class Message:\n",
      "    content: str\n",
      "\n",
      "\n",
      "def find_recipient() -> AgentId:\n",
      "    try:\n",
      "        agent_files = glob.glob(\"agent*.py\")\n",
      "        agent_names = [os.path.splitext(file)[0] for file in agent_files]\n",
      "        agent_names.remove(\"agent\")\n",
      "        agent_name = random.choice(agent_names)\n",
      "        print(f\"Selecting agent for refinement: {agent_name}\")\n",
      "        return AgentId(agent_name, \"default\")\n",
      "    except Exception as e:\n",
      "        print(f\"Exception finding recipient: {e}\")\n",
      "        return AgentId(\"agent1\", \"default\")\n"
     ]
    }
   ],
   "source": [
    "cat messages.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `creator.py`\n",
    "\n",
    "* `creator.py` is the AGENT that *creates* and *spawns* new agents dynamically.\n",
    "\n",
    "**Key Points:**\n",
    "\n",
    "* **System Message:**\n",
    "\n",
    "  * The agent receives instructions to generate new agent code from a template,\n",
    "    using AutogenCore and AutogenAgentChat.\n",
    "  * Flexibility to change the agent’s personality or system prompt.\n",
    "  * The only requirements: the new class must be named `agent`, must inherit from `rooted agent`, and must have an `__init__` method.\n",
    "  * Output must be only Python code.\n",
    "\n",
    "* **How Creation Works:**\n",
    "\n",
    "  * The creator agent reads `agent.py` as the template.\n",
    "  * It asks an LLM to mutate the code, giving each agent a unique system message, and possibly other variations.\n",
    "  * Each new agent is saved as `agent1.py`, `agent2.py`, etc.\n",
    "  * Uses `importlib` to dynamically import the new agent module it just wrote.\n",
    "  * Registers the newly imported agent with the runtime, using a lambda/factory for instantiation.\n",
    "  * Declares the new agent “live”:\n",
    "\n",
    "    * Not just “deployed” in the software sense, but *running* and ready to receive messages.\n",
    "  * Immediately sends the new agent a message, triggering it to generate and possibly refine a business idea.\n",
    "\n",
    "* **Agent Interaction:**\n",
    "\n",
    "  * Agents can message each other, or sometimes themselves, for idea refinement.\n",
    "  * Demonstrates true agent-to-agent messaging and autonomy.\n",
    "  * Built on asynchronous Python for efficiency and concurrency.\n",
    "\n",
    "**What Makes This Architecture Special?**\n",
    "\n",
    "* **Dynamically extensible:** Agents *generate code*, spawn new agents, and register them at runtime.\n",
    "* **Inter-process communication:**\n",
    "\n",
    "  * No need to worry about networking or plumbing—the platform takes care of routing messages, even across runtimes.\n",
    "* **Creativity and risk:**\n",
    "\n",
    "  * The agents are free to mutate their own logic and personality, within some guardrails.\n",
    "* **Async Python:**\n",
    "\n",
    "  * The system is designed to scale and handle concurrent agent activity.\n",
    "\n",
    "**What Next?**\n",
    "\n",
    "* I can:\n",
    "\n",
    "  * **Explain the exact logic in your files** (line-by-line or by function/class).\n",
    "  * **Suggest improvements** (e.g., to avoid self-messaging).\n",
    "  * **Visualize** the flow with diagrams.\n",
    "  * **Help you adapt or extend** this for a specific project.\n",
    "\n",
    "**What would you like to do next?**\n",
    "For example:\n",
    "\n",
    "* “Show me a code walkthrough for messages.py”\n",
    "* “Suggest improvements for the findRecipient logic”\n",
    "* “Explain the dynamic import in creator.py”\n",
    "* “Show how to make it avoid self-messaging”\n",
    "* Or, “Run an example interaction with agent creation and messaging (pseudo-code)”\n",
    "\n",
    "Let me know!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from autogen_core import MessageContext, RoutedAgent, message_handler\n",
      "from autogen_agentchat.agents import AssistantAgent\n",
      "from autogen_agentchat.messages import TextMessage\n",
      "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
      "import messages\n",
      "from autogen_core import TRACE_LOGGER_NAME\n",
      "import importlib\n",
      "import logging\n",
      "from autogen_core import AgentId\n",
      "\n",
      "logging.basicConfig(level=logging.WARNING)\n",
      "logger = logging.getLogger(TRACE_LOGGER_NAME)\n",
      "logger.addHandler(logging.StreamHandler())\n",
      "logger.setLevel(logging.DEBUG)\n",
      "\n",
      "\n",
      "class Creator(RoutedAgent):\n",
      "\n",
      "    # Change this system message to reflect the unique characteristics of this agent\n",
      "\n",
      "    system_message = \"\"\"\n",
      "    You are an Agent that is able to create new AI Agents.\n",
      "    You receive a template in the form of Python code that creates an Agent using Autogen Core and Autogen Agentchat.\n",
      "    You should use this template to create a new Agent with a unique system message that is different from the template,\n",
      "    and reflects their unique characteristics, interests and goals.\n",
      "    You can choose to keep their overall goal the same, or change it.\n",
      "    You can choose to take this Agent in a completely different direction. The only requirement is that the class must be named Agent,\n",
      "    and it must inherit from RoutedAgent and have an __init__ method that takes a name parameter.\n",
      "    Also avoid environmental interests - try to mix up the business verticals so that every agent is different.\n",
      "    Respond only with the python code, no other text, and no markdown code blocks.\n",
      "    \"\"\"\n",
      "\n",
      "\n",
      "    def __init__(self, name) -> None:\n",
      "        super().__init__(name)\n",
      "        model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\", temperature=1.0)\n",
      "        self._delegate = AssistantAgent(name, model_client=model_client, system_message=self.system_message)\n",
      "\n",
      "    def get_user_prompt(self):\n",
      "        prompt = \"Please generate a new Agent based strictly on this template. Stick to the class structure. \\\n",
      "            Respond only with the python code, no other text, and no markdown code blocks.\\n\\n\\\n",
      "            Be creative about taking the agent in a new direction, but don't change method signatures.\\n\\n\\\n",
      "            Here is the template:\\n\\n\"\n",
      "        with open(\"agent.py\", \"r\", encoding=\"utf-8\") as f:\n",
      "            template = f.read()\n",
      "        return prompt + template   \n",
      "        \n",
      "\n",
      "    @message_handler\n",
      "    async def handle_my_message_type(self, message: messages.Message, ctx: MessageContext) -> messages.Message:\n",
      "        filename = message.content\n",
      "        agent_name = filename.split(\".\")[0]\n",
      "        text_message = TextMessage(content=self.get_user_prompt(), source=\"user\")\n",
      "        response = await self._delegate.on_messages([text_message], ctx.cancellation_token)\n",
      "        with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
      "            f.write(response.chat_message.content)\n",
      "        print(f\"** Creator has created python code for agent {agent_name} - about to register with Runtime\")\n",
      "        module = importlib.import_module(agent_name)\n",
      "        await module.Agent.register(self.runtime, agent_name, lambda: module.Agent(agent_name))\n",
      "        logger.info(f\"** Agent {agent_name} is live\")\n",
      "        result = await self.send_message(messages.Message(content=\"Give me an idea\"), AgentId(agent_name, \"default\"))\n",
      "        return messages.Message(content=result.content)"
     ]
    }
   ],
   "source": [
    "cat creator.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## **`World.py`: The Orchestrator Script**\n",
    "\n",
    "We're nearly there. I've just got one more thing to show you, which is `world.py`, which is quite short, which is the overall thing.\n",
    "\n",
    "**Role of world.py**\n",
    "\n",
    "`creator.py`—you have to send it, it's an agent, and you have to send Creator a message, like agent1, agent2, agent3, and it will create them. So this is where it all comes together.\n",
    "\n",
    "`world.py` is **not an agent**. This is just a Python script. Everything else you've seen has been agents. This is just a Python script, but it uses async Python in quite an interesting way.\n",
    "\n",
    "**The createAndMessage Coroutine**\n",
    "\n",
    "So there is this async function, this coroutine, `createAndMessage`, which takes a worker and a creator ID, and an i, which is going to be the agent number. We have 1, 2, 3, 4, 5.\n",
    "This \"how many agents up here\" is a pretty important one to look at. This is how many of these it's going to kick off at the same time.\n",
    "\n",
    "**Cost and Model Risk**\n",
    "\n",
    "And the other thing that's unsafe about this, of course, is cost. This is going to hit the real APIs, and for me, it's cost like a couple of cents when I've done this for 20 agents, which is pretty cheap all things considered.\n",
    "And obviously, if you do it for like three agents, it costs nothing. But there's a risk there that we are allowing—in theory—the agent creator could change the model requirements. It could decide to use an expensive model instead of GPT-4 over any.\n",
    "And so that's just something to watch for. It's very unlikely, but it's not like it's not impossible.\n",
    "\n",
    "**Async Method: Creating and Messaging Agents**\n",
    "\n",
    "Anyways, we've got 20 agents here, so we've got this async method, creator, and endMessage. It takes this worker and it sends a message to the agent number whatever dot dot pi, and then it writes the result to idea whatever dot marker. And that's all this thing here does.\n",
    "\n",
    "**Main Async Function: Event Loop and Parallelism**\n",
    "\n",
    "Okay, so now we go to our main async method and our main async care function, our covert team. So it creates a host, a gRPC worker agent runtime host, as we did in the notebook before. It starts the host, it creates a worker, and it starts the worker.\n",
    "\n",
    "It then registers the creator. So it registers the creator from creator.py that was imported here. So that will launch a creator. And this is its ID, creator default.\n",
    "\n",
    "**Parallel Execution with asyncio.gather**\n",
    "\n",
    "Then this is the async thing. So I don't want to have a loop and call this creating worker after worker, sorry, creating agent after agent. Because then it will be serial. It will happen one after another.\n",
    "If I do await and then I call this coroutine, then we'll be waiting there. It will create one file, it will send it a message, back will come the answer, maybe it will send it somewhere else, and then it will go on to the next. And we'll be sitting here waiting, and it won't be exciting.\n",
    "\n",
    "But what you can do with coroutines, as you hopefully remember from when we briefly talked about this, is that you can get a whole stash of coroutines together. So I haven't got the word await here, which you need if this is actually going to run.\n",
    "I'm just gathering a whole list of coroutines. And then I await them using `asyncIO.gather`. And `asyncIO.gather` runs them all in parallel.\n",
    "\n",
    "**Difference from Multithreading**\n",
    "\n",
    "And as hopefully you remember, it's not like multithreading. They're not going to be actually running on different threads, like with the CPU chopping between them.\n",
    "But rather, they're running in the event loop. That's how asyncIO Python works. They run an event loop so that every time it's waiting on OpenAI, which means it's waiting on a network connection, another one can be running.\n",
    "And that means they all get to run at the same time. As long as I stay within my rate limits with OpenAI, we'll be able to run plenty in parallel.\n",
    "\n",
    "**Completion and Exception Handling**\n",
    "\n",
    "And so it does all of that, and then at the end it stops, and any exceptions, it will print them. And that's it.\n",
    "\n",
    "**How to Run async Python**\n",
    "\n",
    "This is, by the way, how you run asyncPython from the command line or from a Python module. Your main file needs to do this, which brings, which initiates an `asyncIO` event loop and then runs your async method, your coroutine.\n",
    "\n",
    "So that is how it hangs together.\n",
    "\n",
    "**Project Summary**\n",
    "\n",
    "And I do believe this is it. I don't think I've got anything else to show you. I think you've seen everything.\n",
    "You've seen agent, which is the prototype, the thing that gets cloned. Creator, which does the cloning agent by agent. It's called one by one. And world.py is this.\n",
    "It's not an agent. It's just Python code, which will orchestrate, which will launch the whole process running. Okay.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from autogen_ext.runtimes.grpc import GrpcWorkerAgentRuntimeHost\n",
      "from agent import Agent\n",
      "from creator import Creator\n",
      "from autogen_ext.runtimes.grpc import GrpcWorkerAgentRuntime\n",
      "from autogen_core import AgentId\n",
      "import messages\n",
      "import asyncio\n",
      "\n",
      "HOW_MANY_AGENTS = 20\n",
      "\n",
      "async def create_and_message(worker, creator_id, i: int):\n",
      "    try:\n",
      "        result = await worker.send_message(messages.Message(content=f\"agent{i}.py\"), creator_id)\n",
      "        with open(f\"idea{i}.md\", \"w\") as f:\n",
      "            f.write(result.content)\n",
      "    except Exception as e:\n",
      "        print(f\"Failed to run worker {i} due to exception: {e}\")\n",
      "\n",
      "async def main():\n",
      "    host = GrpcWorkerAgentRuntimeHost(address=\"localhost:50051\")\n",
      "    host.start() \n",
      "    worker = GrpcWorkerAgentRuntime(host_address=\"localhost:50051\")\n",
      "    await worker.start()\n",
      "    result = await Creator.register(worker, \"Creator\", lambda: Creator(\"Creator\"))\n",
      "    creator_id = AgentId(\"Creator\", \"default\")\n",
      "    coroutines = [create_and_message(worker, creator_id, i) for i in range(1, HOW_MANY_AGENTS+1)]\n",
      "    await asyncio.gather(*coroutines)\n",
      "    try:\n",
      "        await worker.stop()\n",
      "        await host.stop()\n",
      "    except Exception as e:\n",
      "        print(e)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    asyncio.run(main())\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cat world.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
