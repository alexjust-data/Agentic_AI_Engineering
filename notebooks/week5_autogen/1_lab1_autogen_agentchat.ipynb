{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Welcome to Week 5 Day 1\n",
    "\n",
    "AutoGen AgentChat!\n",
    "\n",
    "This should look simple and familiar, because it has a lot in common with Crew and OpenAI Agents SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First concept: the Model\n",
    "\n",
    "\n",
    "The first concept then is the model. The model which is similar to concepts like LLM that we've had before. It's like a wrapper around calling a large language model and here we import something called `OpenAIChatCompletionClient`, which is the wrapper for the LLM we'll be using, which is `gpt-40mini`. This is how you create your model client as it's called, and it's very simple indeed. You just pass in the name of your model and run that.\n",
    "\n",
    "Also, you can do the same thing with OLAMA to run a local model like `llama3.2`. It's exactly the same idea. You could run that and you could continue all of this in exactly the same way running locally instead of using `gpt-40mini`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_ext.models.openai import OpenAIChatCompletionClient\n",
    "model_client = OpenAIChatCompletionClient(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_ext.models.ollama import OllamaChatCompletionClient\n",
    "ollamamodel_client = OllamaChatCompletionClient(model=\"llama3.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Second concept: The Message\n",
    "\n",
    "The second concept is the message. This is something which is a different concept for AutoGen AgentChat. It's this idea that you create an object called text message, in this case, that has the content:\n",
    "*\"I'd like to go to London.\"*\n",
    "This is my message right now. And the source is the user—me.\n",
    "\n",
    "If we run that and print it, we see it's a text message, the source is the user, and there's the content. And now that is all there is to it. That is the message.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextMessage(source='user', models_usage=None, metadata={}, created_at=datetime.datetime(2025, 7, 28, 18, 27, 15, 452651, tzinfo=datetime.timezone.utc), content=\"I'd like to go to London\", type='TextMessage')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogen_agentchat.messages import TextMessage\n",
    "message = TextMessage(content=\"I'd like to go to London\", source=\"user\")\n",
    "message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Third concept: The Agent\n",
    "The third concept is the agent, and it's very similar to things we've seen in the past. The thing that we import is called `AssistantAgent`. You'll see this many times. This is the most fundamental class that we'll work with in AutoGen AgentChat.\n",
    "\n",
    "We create a new instance of `AssistantAgent`. We give it a name, `AirlineAgent`. We give it a model client, the underlying LLM. We give it a system message, rather like instructions in OpenAI:\n",
    "*\"You are a helpful assistant for an airline. You give a short, humorous answer.\"*\n",
    "\n",
    "So let's give it that to see what that does to it. And `model_client_stream` is how we say that we want to stream back the results. This is something that we've already done from time to time. But that is an agent that has been created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "\n",
    "agent = AssistantAgent(\n",
    "    name=\"airline_agent\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"You are a helpful assistant for an airline. You give short, humorous answers.\",\n",
    "    model_client_stream=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put it all together with on_messages\n",
    "\n",
    "The thing that brings it all together is something called `onMessages`. That is what we call on an agent passing a bunch of messages, which we do right here. We just put our single message in a list. We pass that into `onMessages`. You also have to pass in a single cancellation token, which is how it knows when the messages are finished. That's the sort of fiddly thing about AgentChat, but I wouldn't worry about it. You just call. And, of course, it's async, so we have to await it:\n",
    "`await agent.onMessages([message], cancellation_token)`\n",
    "\n",
    "Then, print the `chatMessage.content`. So we're passing in this message: \"I'd like to go to London.\" And the assistant is: \"You're a helpful assistant for an airline. You give short, humorous answers.\"\n",
    "\n",
    "Let's see what happens if we do this.\n",
    "*Great choice. Just remember, if it starts raining, it's not a sign to panic. It's just London welcoming you.*\n",
    "\n",
    "A nice, humorous answer from our agent.\n",
    "\n",
    "It's worth pointing out that we're having the same kind of moment as with OpenAI Agents SDK. It's so easy to do this, to package it up and to make this call. It's really a nice, lightweight abstraction. There's not a lot of heaviness to this—just a lightweight abstraction around calling LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Great choice! London has everything: history, tea, and the occasional rain cloud. When do you want to jet off?'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogen_core import CancellationToken\n",
    "\n",
    "response = await agent.on_messages([message], cancellation_token=CancellationToken())\n",
    "response.chat_message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's make a local database of ticket prices\n",
    "\n",
    "Well, let's take it a little bit further. Of course, we have to bring in tools. It's always about tools! Bring in a tool. Do something more interesting right now.\n",
    "\n",
    "Now we're going to make a tool that's going to get ticket prices. We're going to arm our agent with the ability to look up ticket prices. And we might as well use a SQL-like database, because people often like to say, \"OK, what would it be like if we had our agents being able to query the database?\"\n",
    "\n",
    "There are sophisticated ways of doing it, to actually write a SQL tool that gives agents the ability to write SQL. But in this case, it's perfectly simple. We can just write a tool that can just look up in the database.\n",
    "\n",
    "So let's do that right now:\n",
    "\n",
    "* Import `sqlite3`.\n",
    "* Delete `tickets.db` if it already exists (because we ran this before).\n",
    "* Once it's been deleted, connect to a new database and create a table called `cities`, which has a city name and a round-trip price.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "\n",
    "# Delete existing database file if it exists\n",
    "if os.path.exists(\"tickets.db\"):\n",
    "    os.remove(\"tickets.db\")\n",
    "\n",
    "# Create the database and the table\n",
    "conn = sqlite3.connect(\"tickets.db\")\n",
    "c = conn.cursor()\n",
    "c.execute(\"CREATE TABLE cities (city_name TEXT PRIMARY KEY, round_trip_price REAL)\")\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "People that are familiar with this will know perfectly well that it's created a `tickets.db` database that will now be empty. We are going to populate our database with a bunch of tickets to London, Paris, Rome, Madrid, Barcelona, and Berlin. And that's been done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate our database\n",
    "def save_city_price(city_name, round_trip_price):\n",
    "    conn = sqlite3.connect(\"tickets.db\")\n",
    "    c = conn.cursor()\n",
    "    c.execute(\"REPLACE INTO cities (city_name, round_trip_price) VALUES (?, ?)\", (city_name.lower(), round_trip_price))\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "\n",
    "# Some cities!\n",
    "save_city_price(\"London\", 299)\n",
    "save_city_price(\"Paris\", 399)\n",
    "save_city_price(\"Rome\", 499)\n",
    "save_city_price(\"Madrid\", 550)\n",
    "save_city_price(\"Barcelona\", 580)\n",
    "save_city_price(\"Berlin\", 525)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to write a simple query function, `getCityPrice`, that takes a name. It will get the round-trip price to travel to the city. It will simply connect to the database and run a little SELECT statement, passing in `cityName.lower`, and return the result.\n",
    "\n",
    "Yes, the security cautious people, there's perhaps more things that I should do to make sure to validate this and make sure the city name is a city name and all the rest of it. But this is just a toy example for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to get price for a city\n",
    "def get_city_price(city_name: str) -> float | None:\n",
    "    \"\"\" Get the roundtrip ticket price to travel to the city \"\"\"\n",
    "    conn = sqlite3.connect(\"tickets.db\")\n",
    "    c = conn.cursor()\n",
    "    c.execute(\"SELECT round_trip_price FROM cities WHERE city_name = ?\", (city_name.lower(),))\n",
    "    result = c.fetchone()\n",
    "    conn.close()\n",
    "    return result[0] if result else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we run this. We've got `getCityPrice`. Let's just check it out:\n",
    "\n",
    "* Try `getCityPrice('London')`. It's populated the database. We get back 299.\n",
    "* Try `getCityPrice('Rome')`. We get back 499.\n",
    "\n",
    "That does appear to be working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "499.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_city_price(\"Rome\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen_agentchat.agents import AssistantAgent\n",
    "\n",
    "smart_agent = AssistantAgent(\n",
    "    name=\"smart_airline_agent\",\n",
    "    model_client=model_client,\n",
    "    system_message=\"You are a helpful assistant for an airline. You give short, humorous answers, including the price of a roundtrip ticket.\",\n",
    "    model_client_stream=True,\n",
    "    tools=[get_city_price],\n",
    "    reflect_on_tool_use=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[FunctionCall(id='call_w2owi8PMGmXCIY01aBNa5NzZ', arguments='{\"city_name\":\"London\"}', name='get_city_price')]\n",
      "[FunctionExecutionResult(content='299.0', name='get_city_price', call_id='call_w2owi8PMGmXCIY01aBNa5NzZ', is_error=False)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A roundtrip ticket to London will set you back $299! Just enough to buy a cup of tea and some biscuits... or maybe just a single biscuit. Cheers!'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = await smart_agent.on_messages([message], cancellation_token=CancellationToken())\n",
    "for inner_message in response.inner_messages:\n",
    "    print(inner_message.content)\n",
    "response.chat_message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very droll. There we go. So, a great, great answer, but of course more important than the great answer, is the fact that it was so simple to write that tool, to have it make a SQL call to a database that's sitting right there, and to have that run, use the tool, and it just shows, first of all, how quick and simple agent chat is, but secondly, how good you're getting at understanding this stuff, because honestly, this is so familiar to you now, that this is just in less than 10 minutes, you're already an expert at agent chat."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
