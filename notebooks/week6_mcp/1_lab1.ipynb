{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WELCOME TO THE **M**ODEL **C**ONTEXT **P**ROTOCOL!\n",
    "\n",
    "**Starting the Lab Environment**\n",
    "\n",
    "Remember, with these labs, the first thing you need to do is click up here to set the kernel, something which you know back to front by now. So, welcome to the Model Context Protocol. Welcome back, OpenAI Agents SDK, which I may have mentioned just happens to be my favorite. Please do note that as I go through this and you see the code here, it might look different to you as you go through it in the lab. And that’s a good thing. That’s because I’m constantly updating this. MCP is very much a moving target. It is, honestly, evolving so quickly. There’s new stuff all the time. I try and keep the labs as updated as possible. If you haven’t done this before, then be sure to pull the latest code. There are instructions in the guides, if you’re new to this, on how to use Git and run Git Pull. Make sure you’ve got the latest and you’re good to go.\n",
    "\n",
    "**Important Note for Windows Users**\n",
    "\n",
    "Now, I need to start with some bad news. Some news for Windows PC people. There is a production problem with MCP that means MCP may not work out of the box with Windows PCs. There are some workarounds, but they are hokey and they're not reliable. And there is only one real proper solution to this, and it’s a bit of a bore. You will need to install something called WSL, Windows Subsystem for Linux. That allows you to run a Linux operating system on your PC and be running Cursor connected to that. If you do that, MCP will work fabulously. Thanks to many students who helped me diagnose this and helped me discover that it really is a true, genuine issue, we now know there is no way around it, or at least no reliable way around it, and that the proper solution is using WSL. That is now well confirmed.\n",
    "\n",
    "**Installing WSL (Windows Subsystem for Linux)**\n",
    "\n",
    "So, in order to set up WSL, there are setup instructions. I’ve put a whole section in the setup on WSL—Setup WSL. And it looks like this. \n",
    "\n",
    "---\n",
    "```sh\n",
    "(agents_env) ➜  setup git:(main) ✗ cat SETUP-WSL.md\n",
    "\n",
    "\n",
    "## Master AI Agentic Engineering -  build autonomous AI Agents\n",
    "# Setting up WSL - Windows Subsytem for Linux\n",
    "\n",
    "_NOTE 1: These instructions assume that you've already carried out the PC Setup instructions_\n",
    "_NOTE 2: In Cursor, remember to Right Click on this file in the Explorer and choose \"Open Preview\" to see the formatting._\n",
    "\n",
    "Welcome back to Setup-land, PC people!\n",
    "I expect you're here because ...\n",
    "...\n",
    "...\n",
    "```\n",
    "---\n",
    "\n",
    "I’m not going to record a separate video for it, because honestly, this is easy-peasy stuff. It’s identical to setting up your environment the first time around. You just have to go through it one more time. And it’s just something to hammer through. I’m sorry you have to go through it, especially when you’re so excited about MCP. But at the end of it, it’s going to work.\n",
    "\n",
    "**Filesystem Navigation in WSL**\n",
    "\n",
    "One thing to know about when you're doing this, if you don’t already know this, Windows people, is that in WSL, you need to be aware of whether you are in the home directory of your Linux system—your Linux home directory—or in the home directory of your PC. The stuff that you want to work on should be in your Linux home directory. When you first launch WSL, there are two ways to do it. You can type `wsl`, or you can type `ubuntu`. It’s important to know that if you type `ubuntu`, you go straight into your Linux home directory. So that’s the safer way to do it. Otherwise, just make sure that you change to your Linux home directory. The instructions are in the setup guide.\n",
    "\n",
    "**Mac Users**\n",
    "\n",
    "And for Mac people, you guys are in great shape. You don’t need to worry about any of this. This is unfortunately a PC thing.\n",
    "\n",
    "**Ready to Begin**\n",
    "\n",
    "So hopefully by this point, if you’re a PC person, you have now installed WSL, you’re back here, ready to go. And we’re off to the races. And I barely need to tell you that we start with some imports. And we start by importing and loading our `.env` secrets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "        <td>\n",
    "            <h2 style=\"color:brown;\">To my Windows PC people - an important announcement</h2>\n",
    "            <span style=\"color:brown;\">I have unpleasant news. There's a problem running MCP Servers on Windows PCs; Mac and Linux is fine. This is a known issue as of May 4th, 2025. I asked o3 with Deep Research to try to find workarounds; it <a href=\"https://chatgpt.com/share/6817bbc3-3d0c-8012-9b51-631842470628\">confirmed the issue</a> and confirmed the workaround.<br/><br/>\n",
    "            The workaround is a bit of a bore. It is to take advantage of \"WSL\", the Microsoft approach for running Linux on your PC. You'll need to carry out more setup instructions! But it's quick, and several students have confirmed that this works perfectly for them, then the Week 6 MCP labs work. Plus, WSL is actually a great way to build software on your Windows PC.<br/>\n",
    "            The WSL Setup instructions are in the Setup folder, <a href=\"../setup/SETUP-WSL.md\">in the file called SETUP-WSL.md here</a>. I do hope this only holds you up briefly - you should be back up and running quickly. Oh the joys of working with bleeding-edge technology!<br/><br/>\n",
    "            With many thanks to students Markus, Abhi, Hui-Ling, and several others, for helping me work on it and confirming the fix.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The imports\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from agents import Agent, Runner, trace\n",
    "from agents.mcp import MCPServerStdio\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's use MCP in OpenAI Agents SDK\n",
    "\n",
    "1. Create a Client\n",
    "\n",
    "2. Have it spawn a server\n",
    "\n",
    "3. Collect the tools that the server can use\n",
    "\n",
    "Let's try the Fetch mcp-server that we looked at last week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fetch_params = {\"command\": \"uvx\", \"args\": [\"mcp-server-fetch\"]}\n",
    "\n",
    "async with MCPServerStdio(params=fetch_params, client_session_timeout_seconds=60) as server:\n",
    "    fetch_tools = await server.list_tools()\n",
    "\n",
    "fetch_tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra installation step - if you don't have \"node\" on your computer\n",
    "\n",
    "The next MCP tool uses node (the Javascript Server), and it needs you to have the command 'npx' installed on your computer.\n",
    "\n",
    "**Windows Users take note:** node needs to be installed on your WSL platform, rather than your Windows side.  \n",
    "And some windows users have mentioned that they needed to replace \"npx\" below with a full path to npx to get this to work properly..\n",
    "\n",
    "You may already have this, but if not, here are super clear instructions on exactly what to do, courtesy of our friend.  \n",
    "And thank you to student avid_learner for pointing this out.\n",
    "\n",
    "https://chatgpt.com/share/68103af2-e2dc-8012-b259-bc135a23273b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And now repeat for 2 more!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playwright_params = {\"command\": \"npx\",\"args\": [ \"@playwright/mcp@latest\"]}\n",
    "\n",
    "async with MCPServerStdio(params=playwright_params, client_session_timeout_seconds=60) as server:\n",
    "    playwright_tools = await server.list_tools()\n",
    "\n",
    "playwright_tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sandbox_path = os.path.abspath(os.path.join(os.getcwd(), \"sandbox\"))\n",
    "files_params = {\"command\": \"npx\", \"args\": [\"-y\", \"@modelcontextprotocol/server-filesystem\", sandbox_path]}\n",
    "\n",
    "async with MCPServerStdio(params=files_params,client_session_timeout_seconds=60) as server:\n",
    "    file_tools = await server.list_tools()\n",
    "\n",
    "file_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And now.. bring on the Agent with Tools!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"\"\"\n",
    "You browse the internet to accomplish your instructions.\n",
    "You are highly capable at browsing the internet independently to accomplish your task, \n",
    "including accepting all cookies and clicking 'not now' as\n",
    "appropriate to get to the content you need. If one website isn't fruitful, try another. \n",
    "Be persistent until you have solved your assignment,\n",
    "trying different options and sites as needed.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "async with MCPServerStdio(params=files_params, client_session_timeout_seconds=60) as mcp_server_files:\n",
    "    async with MCPServerStdio(params=playwright_params, client_session_timeout_seconds=60) as mcp_server_browser:\n",
    "        agent = Agent(\n",
    "            name=\"investigator\", \n",
    "            instructions=instructions, \n",
    "            model=\"gpt-4.1-mini\",\n",
    "            mcp_servers=[mcp_server_files, mcp_server_browser]\n",
    "            )\n",
    "        with trace(\"investigate\"):\n",
    "            result = await Runner.run(agent, \"Find a great recipe for Banoffee Pie, then summarize it in markdown to banoffee.md\")\n",
    "            print(result.final_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check out the trace\n",
    "\n",
    "https://platform.openai.com/traces\n",
    "\n",
    "### Now take a look at some MCP marketplaces\n",
    "\n",
    "https://mcp.so\n",
    "\n",
    "https://glama.ai/mcp\n",
    "\n",
    "https://smithery.ai/\n",
    "\n",
    "https://huggingface.co/blog/LLMhacker/top-11-essential-mcp-libraries\n",
    "\n",
    "HuggingFace great community article:\n",
    "https://huggingface.co/blog/Kseniase/mcp\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
