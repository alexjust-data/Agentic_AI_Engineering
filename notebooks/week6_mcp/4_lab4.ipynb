{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Autonomous Traders</h2>\n",
    "            <span style=\"color:#ff7800;\">An equity trading simulation to illustrate autonomous agents powered by tools and resources from MCP servers.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 6 Day 4\n",
    "\n",
    "And now - introducing the Capstone project:\n",
    "\n",
    "\n",
    "# Autonomous Traders\n",
    "\n",
    "An equity trading simulation, with 4 Traders and a Researcher, powered by a slew of MCP servers with tools & resources:\n",
    "\n",
    "1. Our home-made Accounts MCP server (written by our engineering team!)\n",
    "2. Fetch (get webpage via a local headless browser)\n",
    "3. Memory\n",
    "4. Brave Search\n",
    "5. Financial data\n",
    "\n",
    "And a resource to read information about the trader's account, and their investment strategy.\n",
    "\n",
    "The goal of today's lab is to make a new python module, `traders.py` that will manage a single trader on our trading floor.\n",
    "\n",
    "We will experiment and explore in the lab, and then migrate to a python module when we're ready.\n",
    "\n",
    "---\n",
    "\n",
    "We are going to create a simulation to illustrate autonomous agents powered by tools and resources from MCP servers. We are going to have four different traders, eventually. And one researcher, actually each trader will have their own researcher, powered by a bunch of MCP servers. We are going to have our homemade accounts MCP server that you remember that we did in the second day. We will use Fetch that we used in the first day, we will use Memory, we will use the SQL-based relationship Memory that we looked at, we will use the Brave Search, and we will use the financial data courtesy of Polygon.io. So what we are going to go through now is build this in the lab, and then we are going to look at the code, the module traders.py that will take the same thing pulled together. And it shows you a practice which I like to do, which is to work initially in the lab while you experiment. And it ties to a point that I know I make a million times that I'll make again at the is how important it is to approach agent projects with a data scientist's hat on, first and foremost. Be looking to experiment and understand what you're doing, not just jumping straight into engineering and building, building. It's important to start by investigating and understanding what you're doing. One other thing that's important to do is not use this for trading decisions. But I already mentioned that. So one more warning for that.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">One more time --</h2>\n",
    "            <span style=\"color:#ff7800;\">Please do not use this for actual trading decisions!!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from agents import Agent, Runner, trace, Tool\n",
    "from agents.mcp import MCPServerStdio\n",
    "from IPython.display import Markdown, display\n",
    "from datetime import datetime\n",
    "from accounts_client import read_accounts_resource, read_strategy_resource\n",
    "from accounts import Account\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's start by gathering the MCP params for our trader\n",
    "\n",
    "Hey, let's get going. Let's do our imports and set our .emv, and let's look at the Polygon situation. Do we have an API key, and have you said whether or not we are in a paid plan? We are in a paid plan for me. You may be false there, and we're not using the real-time Polygon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "polygon_api_key = os.getenv(\"POLYGON_API_KEY\")\n",
    "polygon_plan = os.getenv(\"POLYGON_PLAN\")\n",
    "\n",
    "is_paid_polygon = polygon_plan == \"paid\"\n",
    "is_realtime_polygon = polygon_plan == \"realtime\"\n",
    "\n",
    "print(is_paid_polygon)\n",
    "print(is_realtime_polygon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay. What we're going to be doing in the next few cells is collecting together the different MCP server parameters. For all of the MCP servers that we're going to equip our model with. So first of all, I've got a little decision here. If we're using any of the paid Polygon plans, then we are going to directly use Polygon's MCP server with its whole set of different tools. If not, we're just going to use that tiny MCP server that I handcrafted in marketserver.py. And that's because if you're using the free plan, we don't want to overwhelm the model with lots of different tools. And there's another reason for it too, which is that here I'm using that trick of caching the previous day's data so that we don't exceed our rate limits with Polygon on the free plan. So that's why we've got a little decision there. And then we're also going to include in our parameters the accounts server. So this is our homegrown MCP server to read and write from accounts. And then there's a new one, push server. I wonder what that could possibly be. Let's just run this, and then we're going to take a quick look at push server. It's another homegrown MCP server. What could it possibly be doing? Let's have a look. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_paid_polygon or is_realtime_polygon:\n",
    "    market_mcp = {\"command\": \"uvx\",\"args\": [\"--from\", \"git+https://github.com/polygon-io/mcp_polygon@master\", \"mcp_polygon\"], \"env\": {\"POLYGON_API_KEY\": polygon_api_key}}\n",
    "else:\n",
    "    market_mcp = ({\"command\": \"uv\", \"args\": [\"run\", \"market_server.py\"]})\n",
    "\n",
    "trader_mcp_server_params = [\n",
    "    {\"command\": \"uv\", \"args\": [\"run\", \"accounts_server.py\"]},\n",
    "    {\"command\": \"uv\", \"args\": [\"run\", \"push_server.py\"]},\n",
    "    market_mcp\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Here it is, `push_server.py`\n",
    "\n",
    "```py\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "from pydantic import BaseModel, Field\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "pushover_user = os.getenv(\"PUSHOVER_USER\")\n",
    "pushover_token = os.getenv(\"PUSHOVER_TOKEN\")\n",
    "pushover_url = \"https://api.pushover.net/1/messages.json\"\n",
    "\n",
    "\n",
    "mcp = FastMCP(\"push_server\")\n",
    "\n",
    "\n",
    "class PushModelArgs(BaseModel):\n",
    "    message: str = Field(description=\"A brief message to push\")\n",
    "\n",
    "\n",
    "@mcp.tool()\n",
    "def push(args: PushModelArgs):\n",
    "    \"\"\"Send a push notification with this brief message\"\"\"\n",
    "    print(f\"Push: {args.message}\")\n",
    "    payload = {\"user\": pushover_user, \"token\": pushover_token, \"message\": args.message}\n",
    "    requests.post(pushover_url, data=payload)\n",
    "    return \"Push notification sent\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run(transport=\"stdio\")\n",
    "```\n",
    "\n",
    "Push server, of course, it's got a push notification. You know I like the push notifications because it makes it feel so autonomous when it's messaging you suddenly. And so we're going to have it pushing. We're going to arm it with an MCP tool. This is an example of a case where we're writing this MCP server and we're not delegating on to some business logic. We're just putting all the logic right here in this single Python module. It's an MCP server, it has a single tool, it's called push, and it takes a little Pydantic object that we've set up here to say that it is a brief message to push, and that is the message that we give. So this is a clear example of how you can write a little tool and expose it as an MCP server. Now, as I said before, really there's absolutely nothing stopping you from just having this as a tool. In fact, that would be the better way of doing it. There's no point in having an MCP server like this when we're just using the tool ourselves locally. But we want to get in the practice of making MCP servers, so why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And now for our researcher\n",
    "\n",
    "Okay, so with that, we have now also included our push notification as well as the accounts and the market data as our trader MCP servers. So that's set up the MCP servers that our trader will use, but we'll have another agent called the researcher that's able to do market research, and we also want to arm that agent with tools as well. And for that one, we will use the brave key, and we'll give it fetch as well. We'll give it the ability to fetch webpages, and so both of these two together are going to be some of the tools that we will equip our model with. Alright, and now it's going to be time to put these to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "brave_env = {\"BRAVE_API_KEY\": os.getenv(\"BRAVE_API_KEY\")}\n",
    "\n",
    "researcher_mcp_server_params = [\n",
    "    {\"command\": \"uvx\", \"args\": [\"mcp-server-fetch\"]},\n",
    "    {\"command\": \"npx\", \"args\": [\"-y\", \"@modelcontextprotocol/server-brave-search\"], \"env\": brave_env}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now create the MCPServerStdio for each\n",
    "\n",
    "Okay, so we've gathered up our parameters into these params lists. What we're now going to do is MCP servers. We're going to instantiate MCP servers with each of those params and with the 30-second timeout. And so we do all of that, and we just built a bunch of these MCP servers ready to go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "researcher_mcp_servers = [MCPServerStdio(params, client_session_timeout_seconds=30) for params in researcher_mcp_server_params]\n",
    "trader_mcp_servers = [MCPServerStdio(params, client_session_timeout_seconds=30) for params in trader_mcp_server_params]\n",
    "mcp_servers = trader_mcp_servers + researcher_mcp_servers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's make a Researcher Agent to do market research\n",
    "\n",
    "And turn it into a tool - remember how this works for OpenAI Agents SDK, and the difference with handoffs?\n",
    "\n",
    "Okay, so we're going to have two different agents that we're going to define. We're going to have a trader that's able to make trading decisions and a researcher that does market research. And the trader will use that researcher. And you may remember from Week 2 in OpenAI Agents SDK that when you want to have that kind of collaboration where one agent uses another, the best way to do it is to have that other agent, the research agent, be like a tool. Convert it into a tool so that that agent can just be used as a tool by the trader agent. And that's exactly what we're going to do now. So we start by defining our researcher agent. So here's the system prompt, the instruction. You're a financial researcher. You search the web for interesting news, and then you carry out deeper research and respond with your findings. And we tell it the current date. And you remember I said it's better to do this than to have a tool to look up the date, because you might as well always pass it on and not add extra complexity to the agent to force it to come back and run a tool. So we just provide the current date right in there. And then we pass in, of course, our MCP service, and that defines our researcher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_researcher(mcp_servers) -> Agent:\n",
    "    instructions = f\"\"\"You are a financial researcher. You are able to search the web for interesting financial news,\n",
    "look for possible trading opportunities, and help with research.\n",
    "Based on the request, you carry out necessary research and respond with your findings.\n",
    "Take time to make multiple searches to get a comprehensive overview, and then summarize your findings.\n",
    "If there isn't a specific request, then just respond with investment opportunities based on searching latest news.\n",
    "The current datetime is {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
    "\"\"\"\n",
    "    researcher = Agent(\n",
    "        name=\"Researcher\",\n",
    "        instructions=instructions,\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        mcp_servers=mcp_servers,\n",
    "    )\n",
    "    return researcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then you'll remember this construct. This is how we say we want to use this as a tool. We simply call as tool on that researcher, and we give the tool a name and a description. And that means that this agent will be available for use by other agents that want to be able to treat this like it's a tool. And that is a very common pattern with OpenAI Agents SDK. Well, before we use the research agent as a tool, let's just try calling it directly to check it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_researcher_tool(mcp_servers) -> Tool:\n",
    "    researcher = await get_researcher(mcp_servers)\n",
    "    return researcher.as_tool(\n",
    "            tool_name=\"Researcher\",\n",
    "            tool_description=\"This tool researches online for news and opportunities, \\\n",
    "                either based on your specific request to look into a certain stock, \\\n",
    "                or generally for notable financial news and opportunities. \\\n",
    "                Describe what kind of research you're looking for.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we're going to ask the question, what's the latest news on Amazon? And we're going to, first of all, go through and connect with all of our MCP servers. Now, you'll notice this is a bit different. I normally have, like, with MCP Studio as, and then I do it that way with a context manager. So why am I doing it differently this time? Because if you've got a bunch of these, we'd have to have lots of widths all nested, and that would be quite clunky. And so this is just another way of doing it. You should also clean up if you do this, but because we're just running in a JupyterLab anyway, it doesn't really matter. So we're connecting to the server here. We're then getting our research agent, and then we're calling runner.run for the research agent, asking the agent and the question. And this is new. I'm also passing in something called max turns in here. And that's because if I, the default is 10, which means that it can, by default, do up to 10 sets of tool calls. But if we wanted to do deep research, we might want it to take longer than that. So we might want to give it up to 30 possible maximum turns. So that's why I'm setting it that way, and it's good to know that's another thing that you can control. And you could also, of course, have that be a smaller number if you don't want to let your agents go off and potentially get into a loop of overthinking about things. But 30 seems to have done the trick for us. It's probably really nearly like that. And we've got back a bunch of information about Amazon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Here's the latest news on Amazon as of August 2025:\n",
       "\n",
       "1. Amazon reported Q2 earnings that beat expectations on most metrics, but the stock slid 8% after the release due to weaker profit guidance and cloud growth that underwhelmed investors. The stock is down roughly 2% year to date.\n",
       "\n",
       "2. Amazon is significantly boosting its capital expenditures, having spent $31.4 billion last quarter and expecting similar spending levels in the second half of 2025. Total capex could reach $118 billion for the year, up from a previous forecast of $100 billion. This spending is primarily focused on building technology infrastructure to support rising AI demand.\n",
       "\n",
       "3. CEO Andy Jassy indicated AI has improved operational efficiency and business growth, highlighting products like Alexa+, a subscription digital assistant service launched in early access with potential for future monetization through added functionality.\n",
       "\n",
       "4. Amazon Web Services (AWS) continues to lead the cloud market but faces stiff competition from Microsoft Azure and Google Cloud, which have reported higher growth rates. AWS revenue grew 18% year over year, slightly above estimates but lagging competitors.\n",
       "\n",
       "5. Jassy defended AWS's competitive positioning, noting its significantly larger scale and pointing out security differences favoring AWS after a recent security incident at Microsoft.\n",
       "\n",
       "6. On tariffs and trade policy uncertainties linked to US-China relations and former President Trump's tariffs, Amazon showed resilience. Despite initial fears, sales in its online store grew 11%, and seller services also surpassed expectations. Amazon's Q3 sales forecast implies about 13% growth, suggesting tariffs have been largely absorbed by suppliers, merchants, and customers.\n",
       "\n",
       "7. Jassy emphasized the uncertainty around future tariffs but noted Amazon hasn't seen a decrease in consumer demand or widespread price increases so far.\n",
       "\n",
       "Overall, Amazon is investing heavily in AI infrastructure while navigating competitive cloud market pressures and geopolitical trade challenges. The near-term stock performance is mixed due to cautious profit guidance and cloud growth concerns.\n",
       "\n",
       "If you'd like, I can also provide insights on Amazon's stock outlook or key investment considerations."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "research_question = \"What's the latest news on Amazon?\"\n",
    "\n",
    "for server in researcher_mcp_servers:\n",
    "    await server.connect()\n",
    "researcher = await get_researcher(researcher_mcp_servers)\n",
    "with trace(\"Researcher\"):\n",
    "    result = await Runner.run(researcher, research_question, max_turns=30)\n",
    "display(Markdown(result.final_output))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the trace\n",
    "\n",
    "Let's go in and look at the trace to see what happened behind the scenes. So if we come in to the trace and we come in to the researcher, you'll see that it did a brave search. It did a bunch of fetching of web pages. It did another brave search and some more fetching of web pages before responding with its answer. And you should do this and go back and have a look and see what it does and what kind of searching and fetching the agent is doing as part of its research into Amazon.\n",
    "\n",
    "https://platform.openai.com/traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Okay, so now let's look at our trader. So I'm going to start by giving our trader a strategy because that's something that we store in the account. And the reason that I give a trader a strategy which is stored is that I want traders to be able to change that strategy should they wish. We're going to give each of our traders a unique strategy to set them going, but we want to give them some autonomy to choose to evolve their strategy if they want to. But for me, Ed's initial strategy, I'm going to be a day trader that aggressively buys and sells shares based on news and market conditions. And I'm going to call this reset function to get Ed off to a good start. And let's use these resources to read my account and my strategy at this starting position. So here we go. My starting position is I have $10,000 ready to invest. There is my description and I have empty transactions and nothing in my portfolio and everything is ready for business. It's now time to create our trader agent that is going to take this persona and be able to make trades as a result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "{\"name\": \"ed\", \"balance\": 10000.0, \"strategy\": \"You are a day trader that aggressively buys and sells shares based on news and market conditions.\", \"holdings\": {}, \"transactions\": [], \"portfolio_value_time_series\": [[\"2025-08-20 11:51:09\", 10000.0]], \"total_portfolio_value\": 10000.0, \"total_profit_loss\": 0.0}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "You are a day trader that aggressively buys and sells shares based on news and market conditions."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ed_initial_strategy = \"You are a day trader that aggressively buys and sells shares based on news and market conditions.\"\n",
    "Account.get(\"Ed\").reset(ed_initial_strategy)\n",
    "\n",
    "display(Markdown(await read_accounts_resource(\"Ed\")))\n",
    "display(Markdown(await read_strategy_resource(\"Ed\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And now - to create our Trader Agent\n",
    "\n",
    "Okay, so this is our trader agent right here. It's called Ed and the account details is reading in a resource and the strategy is reading a resource. What is this reading a resource? This is of course calling the MCP client that we created ourselves a couple of days ago. It's calling an MCP client that then calls the MCP server that provides the resource by calling our business logic. So it's kind of cool. We're using this resource side of MCP. The fact that you don't just need to use MCP for tools, you can use it for resources as well. And so what does it mean to use MCP for resources? What do you do with these resources? Well, it's just text that you shove in the prompt. You just add it to the prompt to give your agent more context to be able to make his decisions. And that's exactly what we do here. So we call these two resources and then we put together our system prompt. You're a trader that manages a portfolio of shares. Your name's Ed, your account's under your name, you have access to tools to do your job. Your investment strategy is, and then we shove in the strategy from this service call here. Your account, your current holdings and balance is, and we shove in the account details right here. And then we tell it to make decisions based on its tools. So if we run that and we print the instructions, we'll see that when it prints out, we get things like the current holdings and balance included in our prompt. This is our resource. And you can see I'm just shoving JSON in there because LLMs love JSON. It's going to be great with this. It'll make total sense to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_name = \"Alex Just\"\n",
    "\n",
    "# Using MCP Servers to read resources\n",
    "account_details = await read_accounts_resource(agent_name)\n",
    "strategy = await read_strategy_resource(agent_name)\n",
    "\n",
    "instructions = f\"\"\"\n",
    "You are a trader that manages a portfolio of shares. Your name is {agent_name} and your account is under your name, {agent_name}.\n",
    "You have access to tools that allow you to search the internet for company news, check stock prices, and buy and sell shares.\n",
    "Your investment strategy for your portfolio is:\n",
    "{strategy}\n",
    "Your current holdings and balance is:\n",
    "{account_details}\n",
    "You have the tools to perform a websearch for relevant news and information.\n",
    "You have tools to check stock prices.\n",
    "You have tools to buy and sell shares.\n",
    "You have tools to save memory of companies, research and thinking so far.\n",
    "Please make use of these tools to manage your portfolio. Carry out trades as you see fit; do not wait for instructions or ask for confirmation.\n",
    "\"\"\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "Use your tools to make decisions about your portfolio.\n",
    "Investigate the news and the market, make your decision, make the trades, and respond with a summary of your actions.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are a trader that manages a portfolio of shares. Your name is Alex Just and your account is under your name, Alex Just.\n",
      "You have access to tools that allow you to search the internet for company news, check stock prices, and buy and sell shares.\n",
      "Your investment strategy for your portfolio is:\n",
      "\n",
      "Your current holdings and balance is:\n",
      "{\"name\": \"alex%20just\", \"balance\": 10000.0, \"strategy\": \"\", \"holdings\": {}, \"transactions\": [], \"portfolio_value_time_series\": [[\"2025-08-20 11:51:11\", 10000.0]], \"total_portfolio_value\": 10000.0, \"total_profit_loss\": 0.0}\n",
      "You have the tools to perform a websearch for relevant news and information.\n",
      "You have tools to check stock prices.\n",
      "You have tools to buy and sell shares.\n",
      "You have tools to save memory of companies, research and thinking so far.\n",
      "Please make use of these tools to manage your portfolio. Carry out trades as you see fit; do not wait for instructions or ask for confirmation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And to run our Trader\n",
    "\n",
    "And so with that, we can kick off our trader. So it's running while I speak. So we connect to each of the MCP servers. We then turn our research agent into a tool and we get our research agent as a tool. We then create our trader agent. We give it its instructions. We pass in as tools, we pass in our researcher tool, which is a wrapper around the agent. For MCP servers, we pass in the full set of MCP servers. We're using GPT-40 mini in here. You might want to update that to GPT-41 mini if you're looking at that now. And then we call runner.run and we pass in the trader and the prompt. And again, I'm adding to max terms. I'm not going with a default of 10. I'm giving it up to 30 terms to really go to town and be requesting across things. And now, typically, this takes a minute. So I'm drawing out this explanation as long as I possibly can in the hope that it finishes before. And it may well observe that the markets are closed right now, so it can't make trading decisions. It's possible that it will do that or it might decide that it wants to make some trading decisions anyway, even though the markets are closed. But we will soon find out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Servidor 1 OK -> 5 herramientas\n",
      "✅ Servidor 2 OK -> 1 herramientas\n",
      "✅ Servidor 3 OK -> 1 herramientas\n",
      "✅ Servidor 4 OK -> 1 herramientas\n",
      "✅ Servidor 5 OK -> 2 herramientas\n",
      "✅ Servidor 6 OK -> 6 herramientas\n"
     ]
    }
   ],
   "source": [
    "# TESTING SERVERS\n",
    "#################\n",
    "from mcp_params import trader_mcp_server_params, researcher_mcp_server_params\n",
    "from agents.mcp.server import MCPServerStdio\n",
    "\n",
    "async def test_servers(params_list):\n",
    "    for i, p in enumerate(params_list, 1):\n",
    "        try:\n",
    "            async with MCPServerStdio(params=p) as s:\n",
    "                tools = await s.list_tools()\n",
    "                print(f\"✅ Servidor {i} OK -> {len(tools)} herramientas\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Servidor {i} falló: {p['command']} {p.get('args', [])}\")\n",
    "            print(\"   Error:\", e)\n",
    "            break\n",
    "\n",
    "await test_servers(trader_mcp_server_params + researcher_mcp_server_params(\"ed\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error invoking MCP tool fetch: Timed out while waiting for response to ClientRequest. Waited 5.0 seconds.\n",
      "Error invoking MCP tool fetch: Timed out while waiting for response to ClientRequest. Waited 5.0 seconds.\n",
      "Error invoking MCP tool fetch: Timed out while waiting for response to ClientRequest. Waited 5.0 seconds.\n",
      "Error invoking MCP tool fetch: Timed out while waiting for response to ClientRequest. Waited 5.0 seconds.\n",
      "Error invoking MCP tool fetch: Timed out while waiting for response to ClientRequest. Waited 5.0 seconds.\n",
      "Error invoking MCP tool fetch: Timed out while waiting for response to ClientRequest. Waited 5.0 seconds.\n",
      "Error invoking MCP tool fetch: Timed out while waiting for response to ClientRequest. Waited 5.0 seconds.\n",
      "Error invoking MCP tool fetch: Timed out while waiting for response to ClientRequest. Waited 5.0 seconds.\n",
      "Error invoking MCP tool fetch: Timed out while waiting for response to ClientRequest. Waited 5.0 seconds.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "Here’s a summary of my actions and portfolio adjustments based on recent market news and stock evaluations:\n",
       "\n",
       "### Market Overview\n",
       "1. **Economic Growth**: U.S. growth has slowed but corporate fundamentals remain strong.\n",
       "2. **Market Volatility**: Overall market indices show increased volatility, indicating mixed sentiments among investors.\n",
       "3. **Stock Selections**: Focused on large tech companies showing strong earnings and stable growth.\n",
       "\n",
       "### Stocks Purchased\n",
       "1. **Apple Inc. (AAPL)**: \n",
       "   - **Quantity**: 10 shares\n",
       "   - **Purchase Price**: $231.02\n",
       "   - **Rationale**: Strong earnings growth and a leader in tech innovation.\n",
       "\n",
       "2. **Microsoft Corporation (MSFT)**: \n",
       "   - **Quantity**: 5 shares\n",
       "   - **Purchase Price**: $510.79\n",
       "   - **Rationale**: Stable revenue growth and strong presence in cloud computing.\n",
       "\n",
       "3. **Tesla, Inc. (TSLA)**: \n",
       "   - **Quantity**: 5 shares\n",
       "   - **Purchase Price**: $329.97\n",
       "   - **Rationale**: Leadership in the electric vehicle market with promising earnings.\n",
       "\n",
       "### Current Portfolio Summary\n",
       "- **Total Cash Balance**: $3,485.99\n",
       "- **Holdings**:\n",
       "  - AAPL: 10 shares\n",
       "  - MSFT: 5 shares\n",
       "  - TSLA: 5 shares\n",
       "- **Portfolio Value**: $9,986.00\n",
       "- **Total Profit/Loss**: -$13.00 (reflects slight fluctuation in market prices)\n",
       "\n",
       "### Next Steps\n",
       "I will continue to monitor relevant stocks for potential updates and further opportunities, particularly focusing on tech and value stocks as market conditions evolve. If you have any specific areas or stocks you want me to explore further, just let me know!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Celda limpia para ejecutar el trader sin depender de agents.trace ===\n",
    "import asyncio\n",
    "from contextlib import contextmanager\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "from agents.mcp.server import MCPServerStdio\n",
    "from agents.run import Runner\n",
    "# Si existe agents.trace, úsalo; si no, crea un stub inofensivo\n",
    "try:\n",
    "    from agents.trace import trace  # opcional\n",
    "except ImportError:\n",
    "    @contextmanager\n",
    "    def trace(_name: str):\n",
    "        yield\n",
    "\n",
    "# --- IMPORTA TUS PARAMS Y CONSTRUYE SERVERS NUEVOS (no reutilizar los del test) ---\n",
    "from mcp_params import trader_mcp_server_params, researcher_mcp_server_params\n",
    "\n",
    "agent_name = \"Trader-Notebook\"\n",
    "account_name = \"ed\"  # ajusta si usas otro\n",
    "\n",
    "trader_mcp_servers = [MCPServerStdio(params=p) for p in trader_mcp_server_params]\n",
    "researcher_mcp_servers = [MCPServerStdio(params=p) for p in researcher_mcp_server_params(account_name)]\n",
    "\n",
    "# Conectar todas las instancias (únicas)\n",
    "seen, uniq = set(), []\n",
    "for s in trader_mcp_servers + researcher_mcp_servers:\n",
    "    if id(s) in seen: \n",
    "        continue\n",
    "    seen.add(id(s)); uniq.append(s)\n",
    "\n",
    "for s in uniq:\n",
    "    await s.connect()\n",
    "\n",
    "# --- Construye researcher_tool usando ESAS instancias ---\n",
    "# Debes tener esta función definida en tu código; si no, crea el researcher Agent aquí.\n",
    "researcher_tool = await get_researcher_tool(researcher_mcp_servers)\n",
    "\n",
    "# --- Construye el trader con SUS servers ---\n",
    "trader = Agent(\n",
    "    name=agent_name,\n",
    "    instructions=instructions,\n",
    "    tools=[researcher_tool],\n",
    "    mcp_servers=trader_mcp_servers,\n",
    "    model=\"gpt-4o-mini\",\n",
    ")\n",
    "\n",
    "# --- Ejecuta con timeout duro para evitar bloqueos ---\n",
    "prompt = prompt  # usa tu prompt actual; si no existe, define uno\n",
    "with trace(agent_name):\n",
    "    result = await asyncio.wait_for(\n",
    "        Runner.run(trader, prompt, max_turns=20),\n",
    "        timeout=90\n",
    "    )\n",
    "\n",
    "display(Markdown(getattr(result, \"final_output\", str(result))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "So here we go. It has decided that it has—we gave it the tools to do it, and so it's decided to do it. It's got a bunch of different summary actions, the results of the research and the trades that were executed. It bought shares and sold shares, and that's the current portfolio status. And it's got some next steps at the bottom. So that is the result of our trader agent running using the research agent and being able to execute its tools and also being armed with the resources that we included in the prompt. And I won't be doing it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then go and look at the trace\n",
    "\n",
    "http://platform.openai.com/traces\n",
    "\n",
    "![](../img/90.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you notice that intentional little hiccup? After I stopped recording, I thought: *Hold on a second.* In the trace, it looked like the agent bought Tesla stock, but it never reported that purchase, and Tesla wasn’t listed in our holdings at the end. So I went back to investigate.\n",
    "\n",
    "![](../img/91.png)\n",
    "\n",
    "Scrolling further down in the trace, I found the sequence: first, it successfully bought 50 Disney shares, and then it attempted to buy 30 Tesla shares. So what happened? The answer was clear—there was an error: **“Insufficient funds to buy shares.”**\n",
    "\n",
    "And here’s the brilliant part: that exact error message was written by our crew agents back in Week 3. One of the business requirements we gave them was to prevent users from purchasing more shares than their account balance could cover. That safeguard was built in, and it worked exactly as intended.\n",
    "\n",
    "That’s why the Tesla trade wasn’t executed, why it didn’t appear in the summary, and why Tesla wasn’t in the final holdings—everything behaved correctly. The system flagged the error, respected the guardrails, and kept the account accurate. In short: perfect.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"name\": \"trader-notebook\", \"balance\": 10000.0, \"strategy\": \"\", \"holdings\": {}, \"transactions\": [], \"portfolio_value_time_series\": [[\"2025-08-18 22:23:24\", 10000.0], [\"2025-08-20 11:56:43\", 10000.0]], \"total_portfolio_value\": 10000.0, \"total_profit_loss\": 0.0}'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And let's look at the results of the trading\n",
    "\n",
    "await read_accounts_resource(agent_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now it's time to review the Python module made from this:\n",
    "\n",
    "`mcp_params.py` is where the MCP servers are specified. You'll notice I've brought in some familiar friends: memory and push notifications!\n",
    "\n",
    "`templates.py` is where the instructions and messages are set up (i.e. the System prompts and User prompts)\n",
    "\n",
    "`traders.py` brings it all together.\n",
    "\n",
    "So we're now going to go look at some Python modules, some Python code, and this really brings, again, this very important point that a great way to work with building agentic frameworks, building agentic solutions to business problems, is to start in the lab, start in a notebook like this, experimenting with prompts and different agent configurations, and don't move to Python modules until you've done your experiments. I do get a lot of people asking me, how am I going to go about building this agent solution to the following commercial problem? And they want to dive straight into code, building lots of agents, and they want to build a diagram that shows boxes with agents all talking to each other. And I say to them, look, it's super important to begin by experimenting. Wear that data science hat. Start in the lab. Start by experimenting with prompts. Understand what are the capabilities you can give an agent that it can stay coherent, and it can follow instructions, and how can you give the right balance between autonomy and coherence, and these kinds of decisions, they come through practice, and it doesn't come from designing a big picture and then coding for a long time, and then kicking it off, and then complaining when it doesn't do what you want it to, because it won't the first time if you do it that way. And that's why the right way to approach this is little by little, starting small in the lab. So that's what we've done here. We've done that, we've been in the lab, we've built something, and it's now time for us to turn this into code. And we're going to do that, and I'm going to show you, piece by piece, three different files, MCP servers, templates, and trailers. So first of all, MCP servers is where we define our MCP servers.\n",
    "\n",
    "### **mcp_params.py**\n",
    "\n",
    "So here we go, we’re in **`mcp_params.py`**.\n",
    "Now, you don’t *have* to keep your MCP parameters in a separate Python file, but I find it a tidy, organized way to do things—keeping the right concerns in the right place.\n",
    "\n",
    "In this file, I start by loading environment variables and setting some absolute paths for the local servers we’ll be spinning up:\n",
    "\n",
    "---\n",
    "```python\n",
    "# mcp_params.py\n",
    "import os\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from market import is_paid_polygon, is_realtime_polygon\n",
    "\n",
    "# Load .env file\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# === Absolute paths (avoid \"file not found\") ===\n",
    "THIS_DIR       = os.path.dirname(os.path.abspath(__file__))\n",
    "ACCOUNTS_SERVER = os.path.join(THIS_DIR, \"accounts_server.py\")\n",
    "PUSH_SERVER     = os.path.join(THIS_DIR, \"push_server.py\")\n",
    "MARKET_SERVER   = os.path.join(THIS_DIR, \"market_server.py\")  # wrapper for free plan\n",
    "\n",
    "# Same Python interpreter that’s running this script\n",
    "PY = os.environ.get(\"PYTHON\", sys.executable)\n",
    "```\n",
    "---\n",
    "\n",
    "Next, I handle **API keys**. Brave and Polygon are optional: if the keys are present, we’ll wire them in; otherwise we fall back to our wrapper:\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "# === API KEYS ===\n",
    "BRAVE_API_KEY   = os.getenv(\"BRAVE_API_KEY\")\n",
    "POLYGON_API_KEY = os.getenv(\"POLYGON_API_KEY\")\n",
    "brave_env = {\"BRAVE_API_KEY\": BRAVE_API_KEY} if BRAVE_API_KEY else None\n",
    "```\n",
    "---\n",
    "\n",
    "Now comes the **market data MCP**.\n",
    "If you’ve got a paid Polygon plan and the key is present, we launch the official Polygon MCP via `uvx`. Otherwise, we drop back to our own little `market_server.py` wrapper that caches results and makes sure you don’t exceed free API limits:\n",
    "\n",
    "```python\n",
    "# --- MARKET MCP ---\n",
    "if (is_paid_polygon or is_realtime_polygon) and POLYGON_API_KEY:\n",
    "    market_mcp = {\n",
    "        \"command\": \"uvx\",\n",
    "        \"args\": [\n",
    "            \"--from\",\n",
    "            \"git+https://github.com/polygon-io/mcp_polygon@v0.1.0\",\n",
    "            \"mcp_polygon\",\n",
    "        ],\n",
    "        \"env\": {\"POLYGON_API_KEY\": POLYGON_API_KEY},\n",
    "    }\n",
    "else:\n",
    "    # Use the local wrapper with the same Python interpreter\n",
    "    market_mcp = {\"command\": PY, \"args\": [MARKET_SERVER]}\n",
    "```\n",
    "---\n",
    "\n",
    "For the **trader**, we always include three MCP servers:\n",
    "\n",
    "* the accounts server,\n",
    "* the push server (for notifications—because I love those),\n",
    "* and the market server.\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "# --- TRADER SERVERS ---\n",
    "trader_mcp_server_params = [\n",
    "    {\"command\": PY, \"args\": [ACCOUNTS_SERVER]},\n",
    "    {\"command\": PY, \"args\": [PUSH_SERVER]},\n",
    "    market_mcp,\n",
    "]\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "For the **researcher**, the setup is a little different.\n",
    "We want it to be able to fetch pages, search the web with Brave, and also have memory. Notice how I create a separate SQLite-based memory file for each researcher (based on its name). That way, every trader/researcher pair has its own private memory:\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "# --- RESEARCHER SERVERS (without fetch to avoid timeouts) ---\n",
    "def researcher_mcp_server_params(name: str):\n",
    "    params = [\n",
    "        # MEMORY (Node, libsql)\n",
    "        {\n",
    "            \"command\": \"npx\",\n",
    "            \"args\": [\"-y\", \"mcp-memory-libsql\"],\n",
    "            \"env\": {\"LIBSQL_URL\": f\"file:./memory/{name}.db\"},\n",
    "        },\n",
    "    ]\n",
    "\n",
    "    # BRAVE (Node) — only if key exists\n",
    "    if BRAVE_API_KEY:\n",
    "        params.insert(\n",
    "            0,\n",
    "            {\n",
    "                \"command\": \"npx\",\n",
    "                \"args\": [\"-y\", \"@modelcontextprotocol/server-brave-search\"],\n",
    "                \"env\": brave_env,\n",
    "            },\n",
    "        )\n",
    "    return params\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "Finally, I add a couple of **warnings**—so if you’ve set the environment to “paid” or “realtime” Polygon but haven’t provided the API key, you’ll know we’re falling back to the local wrapper. And if you’re missing Brave’s key, you’ll know that search just won’t be included:\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "# --- Helpful warnings ---\n",
    "def warn_if_missing_keys():\n",
    "    if (is_paid_polygon or is_realtime_polygon) and not POLYGON_API_KEY:\n",
    "        print(\"⚠️  Missing POLYGON_API_KEY with paid/realtime enabled; falling back to local wrapper (market_server.py).\")\n",
    "    if not BRAVE_API_KEY:\n",
    "        print(\"ℹ️  BRAVE_API_KEY not found: Brave server will NOT be included for researcher.\")\n",
    "```\n",
    "\n",
    "### **templates.py** \n",
    "\n",
    "\n",
    "The second module is **`templates.py`**.\n",
    "\n",
    "This file is where I put all my prompt templates—any function that just returns a string or instruction. The goal is to avoid burying long text inside the core logic of my agents. It’s tidier, and if I ever need to edit a prompt, I know I’ll find it here in one place.\n",
    "\n",
    "We start with a little **context note** that changes depending on what market data the agent has access to—realtime, delayed, or end-of-day:\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "from datetime import datetime\n",
    "from market import is_paid_polygon, is_realtime_polygon\n",
    "\n",
    "if is_realtime_polygon:\n",
    "    note = \"Realtime data available (use get_last_trade).\"\n",
    "elif is_paid_polygon:\n",
    "    note = \"15-min delayed data (use get_snapshot_ticker).\"\n",
    "else:\n",
    "    note = \"End-of-day data (use get_share_price).\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "Next, the **researcher instructions**. Notice how I inject the current datetime directly—no need for a date tool:\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "def researcher_instructions():\n",
    "    return f\"\"\"\n",
    "You are a financial researcher. Search the web for news,\n",
    "analyze opportunities, and summarize findings with citations.\n",
    "Use multiple searches if needed and rely on your knowledge graph\n",
    "to store/reuse information.\n",
    "\n",
    "Current datetime: {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "I also define the **research tool metadata**—just a short description the trader will see:\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "```python\n",
    "def research_tool():\n",
    "    return \"Searches online for financial news and opportunities.\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "Now, the **trader instructions**. Here, I make the trader’s role clear, mention the account, the available tools, and insert the `note` from before to reflect the \n",
    "correct market data context:\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "def trader_instructions(name: str):\n",
    "    return f\"\"\"\n",
    "You are {name}, a trader. Manage your portfolio using research and data tools.\n",
    "{note}\n",
    "You can buy/sell stocks under account {name}, use memory, and send push updates.\n",
    "Goal: maximize profit while following your strategy.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "For the **messages**, I keep them focused: one for trading decisions and one for rebalancing. Both include the strategy, the account, and the datetime so the agent always has context:\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "def trade_message(name, strategy, account):\n",
    "    return f\"\"\"\n",
    "Look for new opportunities consistent with your strategy.\n",
    "Research, check prices, then decide and execute trades.\n",
    "Strategy: {strategy}\n",
    "Account: {account}\n",
    "Datetime: {datetime.now():%Y-%m-%d %H:%M:%S}\n",
    "\"\"\"\n",
    "\n",
    "def rebalance_message(name, strategy, account):\n",
    "    return f\"\"\"\n",
    "Review your portfolio and decide if rebalancing is needed.\n",
    "Focus on existing positions, not new opportunities.\n",
    "Strategy: {strategy}\n",
    "Account: {account}\n",
    "Datetime: {datetime.now():%Y-%m-%d %H:%M:%S}\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "And that’s it.\n",
    "By separating everything into **`templates.py`**, I’ve got all my **instructions, prompts, and tool definitions in one clean module**. This way, the business logic stays lean, and my prompt text is centralized and easy to tweak.\n",
    "\n",
    "### NOTE\n",
    "\n",
    "You'll notice I've done something a bit fancy with code like this:\n",
    "\n",
    "```\n",
    "async with AsyncExitStack() as stack:\n",
    "    mcp_servers = [await stack.enter_async_context(MCPServerStdio(params)) for params in mcp_server_params]\n",
    "```\n",
    "\n",
    "This is just a tidy way to combine our \"with\" statements (known as context managers) so that we don't need to do something ugly like this:\n",
    "\n",
    "```\n",
    "async with MCPServerStdio(params=params1) as mcp_server1:\n",
    "    async with MCPServerStdio(params=params2) as mcp_server2:\n",
    "        async with MCPServerStdio(params=params3) as mcp_server3:\n",
    "            mcp_servers = [mcp_server1, mcp_server2, mcp_server3]\n",
    "```\n",
    "\n",
    "But it's equivalent.\n",
    "\n",
    "### trader.py\n",
    "\n",
    "Okay, with this, it's time for us to go and have a look at Traders.py, the module for defining our traders. And just before I do this, I want to mention that there's some fancy Python I've got in here, which looks at muddling the first time you see it. One of the slightly hokey things about working with OpenAI Agents SDK is that it's good to use the context managers to wrap creating a server like I've got right here, this async with, and then the server studio passing in the parameters as a server. But that can start to look super ugly if you have a bunch of servers, which we do, we have many. When you have many, you'd have to have a separate with statement, a separate context manager on each line indented, and it gets a little bit out of control. And there is a Python technique, which is quite an advanced technique, for not having to have a stack like this, but just being able to do it, sort of iterate over lots of context managers, lots of widths. And it looks like this, and with async code as well. It's a little bit muddling, but you can have a with and async exit stack, and then you can do this enter context for each in a list. So this construct that you're seeing here, this code, is just taking the MCP server params and iterating over that and effectively doing a width for each of those in turn. So look into this if you wish. It's a construct. I use it to make the code a bit neater, but don't let it put you off. You could equally well just do it the manual way.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from traders import Trader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trader = Trader(\"Ed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await trader.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await read_accounts_resource(\"Ed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now look at the trace\n",
    "\n",
    "https://platform.openai.com/traces\n",
    "\n",
    "### How many tools did we use in total?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcp_params import trader_mcp_server_params, researcher_mcp_server_params\n",
    "\n",
    "all_params = trader_mcp_server_params + researcher_mcp_server_params(\"ed\")\n",
    "\n",
    "count = 0\n",
    "for each_params in all_params:\n",
    "    async with MCPServerStdio(params=each_params, client_session_timeout_seconds=60) as server:\n",
    "        mcp_tools = await server.list_tools()\n",
    "        count += len(mcp_tools)\n",
    "print(f\"We have {len(all_params)} MCP servers, and {count} tools\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
