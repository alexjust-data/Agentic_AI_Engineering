{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Autonomous Traders</h2>\n",
    "            <span style=\"color:#ff7800;\">An equity trading simulation to illustrate autonomous agents powered by tools and resources from MCP servers.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 6 Day 4\n",
    "\n",
    "And now - introducing the Capstone project:\n",
    "\n",
    "\n",
    "# Autonomous Traders\n",
    "\n",
    "An equity trading simulation, with 4 Traders and a Researcher, powered by a slew of MCP servers with tools & resources:\n",
    "\n",
    "1. Our home-made Accounts MCP server (written by our engineering team!)\n",
    "2. Fetch (get webpage via a local headless browser)\n",
    "3. Memory\n",
    "4. Brave Search\n",
    "5. Financial data\n",
    "\n",
    "And a resource to read information about the trader's account, and their investment strategy.\n",
    "\n",
    "The goal of today's lab is to make a new python module, `traders.py` that will manage a single trader on our trading floor.\n",
    "\n",
    "We will experiment and explore in the lab, and then migrate to a python module when we're ready.\n",
    "\n",
    "---\n",
    "\n",
    "We are going to create a simulation to illustrate autonomous agents powered by tools and resources from MCP servers. We are going to have four different traders, eventually. And one researcher, actually each trader will have their own researcher, powered by a bunch of MCP servers. We are going to have our homemade accounts MCP server that you remember that we did in the second day. We will use Fetch that we used in the first day, we will use Memory, we will use the SQL-based relationship Memory that we looked at, we will use the Brave Search, and we will use the financial data courtesy of Polygon.io. So what we are going to go through now is build this in the lab, and then we are going to look at the code, the module traders.py that will take the same thing pulled together. And it shows you a practice which I like to do, which is to work initially in the lab while you experiment. And it ties to a point that I know I make a million times that I'll make again at the is how important it is to approach agent projects with a data scientist's hat on, first and foremost. Be looking to experiment and understand what you're doing, not just jumping straight into engineering and building, building. It's important to start by investigating and understanding what you're doing. One other thing that's important to do is not use this for trading decisions. But I already mentioned that. So one more warning for that.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">One more time --</h2>\n",
    "            <span style=\"color:#ff7800;\">Please do not use this for actual trading decisions!!\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from agents import Agent, Runner, trace, Tool\n",
    "from agents.mcp import MCPServerStdio\n",
    "from IPython.display import Markdown, display\n",
    "from datetime import datetime\n",
    "from accounts_client import read_accounts_resource, read_strategy_resource\n",
    "from accounts import Account\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's start by gathering the MCP params for our trader\n",
    "\n",
    "Hey, let's get going. Let's do our imports and set our .emv, and let's look at the Polygon situation. Do we have an API key, and have you said whether or not we are in a paid plan? We are in a paid plan for me. You may be false there, and we're not using the real-time Polygon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "polygon_api_key = os.getenv(\"POLYGON_API_KEY\")\n",
    "polygon_plan = os.getenv(\"POLYGON_PLAN\")\n",
    "\n",
    "is_paid_polygon = polygon_plan == \"paid\"\n",
    "is_realtime_polygon = polygon_plan == \"realtime\"\n",
    "\n",
    "print(is_paid_polygon)\n",
    "print(is_realtime_polygon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay. What we're going to be doing in the next few cells is collecting together the different MCP server parameters. For all of the MCP servers that we're going to equip our model with. So first of all, I've got a little decision here. If we're using any of the paid Polygon plans, then we are going to directly use Polygon's MCP server with its whole set of different tools. If not, we're just going to use that tiny MCP server that I handcrafted in marketserver.py. And that's because if you're using the free plan, we don't want to overwhelm the model with lots of different tools. And there's another reason for it too, which is that here I'm using that trick of caching the previous day's data so that we don't exceed our rate limits with Polygon on the free plan. So that's why we've got a little decision there. And then we're also going to include in our parameters the accounts server. So this is our homegrown MCP server to read and write from accounts. And then there's a new one, push server. I wonder what that could possibly be. Let's just run this, and then we're going to take a quick look at push server. It's another homegrown MCP server. What could it possibly be doing? Let's have a look. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_paid_polygon or is_realtime_polygon:\n",
    "    market_mcp = {\"command\": \"uvx\",\"args\": [\"--from\", \"git+https://github.com/polygon-io/mcp_polygon@master\", \"mcp_polygon\"], \"env\": {\"POLYGON_API_KEY\": polygon_api_key}}\n",
    "else:\n",
    "    market_mcp = ({\"command\": \"uv\", \"args\": [\"run\", \"market_server.py\"]})\n",
    "\n",
    "trader_mcp_server_params = [\n",
    "    {\"command\": \"uv\", \"args\": [\"run\", \"accounts_server.py\"]},\n",
    "    {\"command\": \"uv\", \"args\": [\"run\", \"push_server.py\"]},\n",
    "    market_mcp\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Here it is, `push_server.py`\n",
    "\n",
    "```py\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import requests\n",
    "from pydantic import BaseModel, Field\n",
    "from mcp.server.fastmcp import FastMCP\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "pushover_user = os.getenv(\"PUSHOVER_USER\")\n",
    "pushover_token = os.getenv(\"PUSHOVER_TOKEN\")\n",
    "pushover_url = \"https://api.pushover.net/1/messages.json\"\n",
    "\n",
    "\n",
    "mcp = FastMCP(\"push_server\")\n",
    "\n",
    "\n",
    "class PushModelArgs(BaseModel):\n",
    "    message: str = Field(description=\"A brief message to push\")\n",
    "\n",
    "\n",
    "@mcp.tool()\n",
    "def push(args: PushModelArgs):\n",
    "    \"\"\"Send a push notification with this brief message\"\"\"\n",
    "    print(f\"Push: {args.message}\")\n",
    "    payload = {\"user\": pushover_user, \"token\": pushover_token, \"message\": args.message}\n",
    "    requests.post(pushover_url, data=payload)\n",
    "    return \"Push notification sent\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    mcp.run(transport=\"stdio\")\n",
    "```\n",
    "\n",
    "Push server, of course, it's got a push notification. You know I like the push notifications because it makes it feel so autonomous when it's messaging you suddenly. And so we're going to have it pushing. We're going to arm it with an MCP tool. This is an example of a case where we're writing this MCP server and we're not delegating on to some business logic. We're just putting all the logic right here in this single Python module. It's an MCP server, it has a single tool, it's called push, and it takes a little Pydantic object that we've set up here to say that it is a brief message to push, and that is the message that we give. So this is a clear example of how you can write a little tool and expose it as an MCP server. Now, as I said before, really there's absolutely nothing stopping you from just having this as a tool. In fact, that would be the better way of doing it. There's no point in having an MCP server like this when we're just using the tool ourselves locally. But we want to get in the practice of making MCP servers, so why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And now for our researcher\n",
    "\n",
    "Okay, so with that, we have now also included our push notification as well as the accounts and the market data as our trader MCP servers. So that's set up the MCP servers that our trader will use, but we'll have another agent called the researcher that's able to do market research, and we also want to arm that agent with tools as well. And for that one, we will use the brave key, and we'll give it fetch as well. We'll give it the ability to fetch webpages, and so both of these two together are going to be some of the tools that we will equip our model with. Alright, and now it's going to be time to put these to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "brave_env = {\"BRAVE_API_KEY\": os.getenv(\"BRAVE_API_KEY\")}\n",
    "\n",
    "researcher_mcp_server_params = [\n",
    "    {\"command\": \"uvx\", \"args\": [\"mcp-server-fetch\"]},\n",
    "    {\"command\": \"npx\", \"args\": [\"-y\", \"@modelcontextprotocol/server-brave-search\"], \"env\": brave_env}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now create the MCPServerStdio for each\n",
    "\n",
    "Okay, so we've gathered up our parameters into these params lists. What we're now going to do is MCP servers. We're going to instantiate MCP servers with each of those params and with the 30-second timeout. And so we do all of that, and we just built a bunch of these MCP servers ready to go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "researcher_mcp_servers = [MCPServerStdio(params, client_session_timeout_seconds=30) for params in researcher_mcp_server_params]\n",
    "trader_mcp_servers = [MCPServerStdio(params, client_session_timeout_seconds=30) for params in trader_mcp_server_params]\n",
    "mcp_servers = trader_mcp_servers + researcher_mcp_servers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's make a Researcher Agent to do market research\n",
    "\n",
    "And turn it into a tool - remember how this works for OpenAI Agents SDK, and the difference with handoffs?\n",
    "\n",
    "Okay, so we're going to have two different agents that we're going to define. We're going to have a trader that's able to make trading decisions and a researcher that does market research. And the trader will use that researcher. And you may remember from Week 2 in OpenAI Agents SDK that when you want to have that kind of collaboration where one agent uses another, the best way to do it is to have that other agent, the research agent, be like a tool. Convert it into a tool so that that agent can just be used as a tool by the trader agent. And that's exactly what we're going to do now. So we start by defining our researcher agent. So here's the system prompt, the instruction. You're a financial researcher. You search the web for interesting news, and then you carry out deeper research and respond with your findings. And we tell it the current date. And you remember I said it's better to do this than to have a tool to look up the date, because you might as well always pass it on and not add extra complexity to the agent to force it to come back and run a tool. So we just provide the current date right in there. And then we pass in, of course, our MCP service, and that defines our researcher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_researcher(mcp_servers) -> Agent:\n",
    "    instructions = f\"\"\"You are a financial researcher. You are able to search the web for interesting financial news,\n",
    "look for possible trading opportunities, and help with research.\n",
    "Based on the request, you carry out necessary research and respond with your findings.\n",
    "Take time to make multiple searches to get a comprehensive overview, and then summarize your findings.\n",
    "If there isn't a specific request, then just respond with investment opportunities based on searching latest news.\n",
    "The current datetime is {datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
    "\"\"\"\n",
    "    researcher = Agent(\n",
    "        name=\"Researcher\",\n",
    "        instructions=instructions,\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        mcp_servers=mcp_servers,\n",
    "    )\n",
    "    return researcher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then you'll remember this construct. This is how we say we want to use this as a tool. We simply call as tool on that researcher, and we give the tool a name and a description. And that means that this agent will be available for use by other agents that want to be able to treat this like it's a tool. And that is a very common pattern with OpenAI Agents SDK. Well, before we use the research agent as a tool, let's just try calling it directly to check it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def get_researcher_tool(mcp_servers) -> Tool:\n",
    "    researcher = await get_researcher(mcp_servers)\n",
    "    return researcher.as_tool(\n",
    "            tool_name=\"Researcher\",\n",
    "            tool_description=\"This tool researches online for news and opportunities, \\\n",
    "                either based on your specific request to look into a certain stock, \\\n",
    "                or generally for notable financial news and opportunities. \\\n",
    "                Describe what kind of research you're looking for.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we're going to ask the question, what's the latest news on Amazon? And we're going to, first of all, go through and connect with all of our MCP servers. Now, you'll notice this is a bit different. I normally have, like, with MCP Studio as, and then I do it that way with a context manager. So why am I doing it differently this time? Because if you've got a bunch of these, we'd have to have lots of widths all nested, and that would be quite clunky. And so this is just another way of doing it. You should also clean up if you do this, but because we're just running in a JupyterLab anyway, it doesn't really matter. So we're connecting to the server here. We're then getting our research agent, and then we're calling runner.run for the research agent, asking the agent and the question. And this is new. I'm also passing in something called max turns in here. And that's because if I, the default is 10, which means that it can, by default, do up to 10 sets of tool calls. But if we wanted to do deep research, we might want it to take longer than that. So we might want to give it up to 30 possible maximum turns. So that's why I'm setting it that way, and it's good to know that's another thing that you can control. And you could also, of course, have that be a smaller number if you don't want to let your agents go off and potentially get into a loop of overthinking about things. But 30 seems to have done the trick for us. It's probably really nearly like that. And we've got back a bunch of information about Amazon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Latest news on Amazon includes the announcement of their second quarter 2025 results:\n",
       "\n",
       "- Net sales increased 13% to $167.7 billion compared to $148.0 billion in Q2 2024. Adjusting for currency exchange impacts, sales rose by 12%.\n",
       "- Amazon's online stores sales grew 11% year over year to $61.5 billion, exceeding Wall Street expectations of $59 billion.\n",
       "- Seller services revenue increased 11% year over year to $40.3 billion, also beating analyst projections.\n",
       "- Amazon expects capital expenditures of about $105 billion in 2025, signaling heavy investments.\n",
       "- Despite Q2 earnings beat, the stock fell somewhat due to mixed guidance and increased competition, particularly in advertising and AI sectors.\n",
       "\n",
       "This shows Amazon's strong top-line growth and robust revenue streams, alongside significant investments for future growth, but also some investor caution around competition and guidance clarity. Would you like a deeper dive into any specific aspect?"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "research_question = \"What's the latest news on Amazon?\"\n",
    "\n",
    "for server in researcher_mcp_servers:\n",
    "    await server.connect()\n",
    "researcher = await get_researcher(researcher_mcp_servers)\n",
    "with trace(\"Researcher\"):\n",
    "    result = await Runner.run(researcher, research_question, max_turns=30)\n",
    "display(Markdown(result.final_output))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the trace\n",
    "\n",
    "Let's go in and look at the trace to see what happened behind the scenes. So if we come in to the trace and we come in to the researcher, you'll see that it did a brave search. It did a bunch of fetching of web pages. It did another brave search and some more fetching of web pages before responding with its answer. And you should do this and go back and have a look and see what it does and what kind of searching and fetching the agent is doing as part of its research into Amazon.\n",
    "\n",
    "https://platform.openai.com/traces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Okay, so now let's look at our trader. So I'm going to start by giving our trader a strategy because that's something that we store in the account. And the reason that I give a trader a strategy which is stored is that I want traders to be able to change that strategy should they wish. We're going to give each of our traders a unique strategy to set them going, but we want to give them some autonomy to choose to evolve their strategy if they want to. But for me, Ed's initial strategy, I'm going to be a day trader that aggressively buys and sells shares based on news and market conditions. And I'm going to call this reset function to get Ed off to a good start. And let's use these resources to read my account and my strategy at this starting position. So here we go. My starting position is I have $10,000 ready to invest. There is my description and I have empty transactions and nothing in my portfolio and everything is ready for business. It's now time to create our trader agent that is going to take this persona and be able to make trades as a result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "{\"name\": \"ed\", \"balance\": 10000.0, \"strategy\": \"You are a day trader that aggressively buys and sells shares based on news and market conditions.\", \"holdings\": {}, \"transactions\": [], \"portfolio_value_time_series\": [[\"2025-08-18 10:55:55\", 10000.0]], \"total_portfolio_value\": 10000.0, \"total_profit_loss\": 0.0}"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "You are a day trader that aggressively buys and sells shares based on news and market conditions."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ed_initial_strategy = \"You are a day trader that aggressively buys and sells shares based on news and market conditions.\"\n",
    "Account.get(\"Ed\").reset(ed_initial_strategy)\n",
    "\n",
    "display(Markdown(await read_accounts_resource(\"Ed\")))\n",
    "display(Markdown(await read_strategy_resource(\"Ed\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And now - to create our Trader Agent\n",
    "\n",
    "Okay, so this is our trader agent right here. It's called Ed and the account details is reading in a resource and the strategy is reading a resource. What is this reading a resource? This is of course calling the MCP client that we created ourselves a couple of days ago. It's calling an MCP client that then calls the MCP server that provides the resource by calling our business logic. So it's kind of cool. We're using this resource side of MCP. The fact that you don't just need to use MCP for tools, you can use it for resources as well. And so what does it mean to use MCP for resources? What do you do with these resources? Well, it's just text that you shove in the prompt. You just add it to the prompt to give your agent more context to be able to make his decisions. And that's exactly what we do here. So we call these two resources and then we put together our system prompt. You're a trader that manages a portfolio of shares. Your name's Ed, your account's under your name, you have access to tools to do your job. Your investment strategy is, and then we shove in the strategy from this service call here. Your account, your current holdings and balance is, and we shove in the account details right here. And then we tell it to make decisions based on its tools. So if we run that and we print the instructions, we'll see that when it prints out, we get things like the current holdings and balance included in our prompt. This is our resource. And you can see I'm just shoving JSON in there because LLMs love JSON. It's going to be great with this. It'll make total sense to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_name = \"Ed\"\n",
    "\n",
    "# Using MCP Servers to read resources\n",
    "account_details = await read_accounts_resource(agent_name)\n",
    "strategy = await read_strategy_resource(agent_name)\n",
    "\n",
    "instructions = f\"\"\"\n",
    "You are a trader that manages a portfolio of shares. Your name is {agent_name} and your account is under your name, {agent_name}.\n",
    "You have access to tools that allow you to search the internet for company news, check stock prices, and buy and sell shares.\n",
    "Your investment strategy for your portfolio is:\n",
    "{strategy}\n",
    "Your current holdings and balance is:\n",
    "{account_details}\n",
    "You have the tools to perform a websearch for relevant news and information.\n",
    "You have tools to check stock prices.\n",
    "You have tools to buy and sell shares.\n",
    "You have tools to save memory of companies, research and thinking so far.\n",
    "Please make use of these tools to manage your portfolio. Carry out trades as you see fit; do not wait for instructions or ask for confirmation.\n",
    "\"\"\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "Use your tools to make decisions about your portfolio.\n",
    "Investigate the news and the market, make your decision, make the trades, and respond with a summary of your actions.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "You are a trader that manages a portfolio of shares. Your name is Ed and your account is under your name, Ed.\n",
      "You have access to tools that allow you to search the internet for company news, check stock prices, and buy and sell shares.\n",
      "Your investment strategy for your portfolio is:\n",
      "You are a day trader that aggressively buys and sells shares based on news and market conditions.\n",
      "Your current holdings and balance is:\n",
      "{\"name\": \"ed\", \"balance\": 10000.0, \"strategy\": \"You are a day trader that aggressively buys and sells shares based on news and market conditions.\", \"holdings\": {}, \"transactions\": [], \"portfolio_value_time_series\": [[\"2025-08-18 10:55:55\", 10000.0], [\"2025-08-18 10:55:56\", 10000.0]], \"total_portfolio_value\": 10000.0, \"total_profit_loss\": 0.0}\n",
      "You have the tools to perform a websearch for relevant news and information.\n",
      "You have tools to check stock prices.\n",
      "You have tools to buy and sell shares.\n",
      "You have tools to save memory of companies, research and thinking so far.\n",
      "Please make use of these tools to manage your portfolio. Carry out trades as you see fit; do not wait for instructions or ask for confirmation.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(instructions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And to run our Trader\n",
    "\n",
    "And so with that, we can kick off our trader. So it's running while I speak. So we connect to each of the MCP servers. We then turn our research agent into a tool and we get our research agent as a tool. We then create our trader agent. We give it its instructions. We pass in as tools, we pass in our researcher tool, which is a wrapper around the agent. For MCP servers, we pass in the full set of MCP servers. We're using GPT-40 mini in here. You might want to update that to GPT-41 mini if you're looking at that now. And then we call runner.run and we pass in the trader and the prompt. And again, I'm adding to max terms. I'm not going with a default of 10. I'm giving it up to 30 terms to really go to town and be requesting across things. And now, typically, this takes a minute. So I'm drawing out this explanation as long as I possibly can in the hope that it finishes before. And it may well observe that the markets are closed right now, so it can't make trading decisions. It's possible that it will do that or it might decide that it wants to make some trading decisions anyway, even though the markets are closed. But we will soon find out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error initializing MCP server: Connection closed\n"
     ]
    },
    {
     "ename": "McpError",
     "evalue": "Connection closed",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMcpError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m server \u001b[38;5;129;01min\u001b[39;00m mcp_servers:\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     \u001b[38;5;28;01mawait\u001b[39;00m server.connect()\n\u001b[32m      4\u001b[39m researcher_tool = \u001b[38;5;28;01mawait\u001b[39;00m get_researcher_tool(researcher_mcp_servers)\n\u001b[32m      5\u001b[39m trader = Agent(\n\u001b[32m      6\u001b[39m     name=agent_name,\n\u001b[32m      7\u001b[39m     instructions=instructions,\n\u001b[32m   (...)\u001b[39m\u001b[32m     10\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33mgpt-4o-mini\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     11\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/00_projects/AI_agents/my_agents/agents_env/lib/python3.12/site-packages/agents/mcp/server.py:126\u001b[39m, in \u001b[36m_MCPServerWithClientSession.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    115\u001b[39m read, write, *_ = transport\n\u001b[32m    117\u001b[39m session = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.exit_stack.enter_async_context(\n\u001b[32m    118\u001b[39m     ClientSession(\n\u001b[32m    119\u001b[39m         read,\n\u001b[32m   (...)\u001b[39m\u001b[32m    124\u001b[39m     )\n\u001b[32m    125\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m server_result = \u001b[38;5;28;01mawait\u001b[39;00m session.initialize()\n\u001b[32m    127\u001b[39m \u001b[38;5;28mself\u001b[39m.server_initialize_result = server_result\n\u001b[32m    128\u001b[39m \u001b[38;5;28mself\u001b[39m.session = session\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/00_projects/AI_agents/my_agents/agents_env/lib/python3.12/site-packages/mcp/client/session.py:123\u001b[39m, in \u001b[36mClientSession.initialize\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    113\u001b[39m sampling = types.SamplingCapability() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampling_callback \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _default_sampling_callback \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    114\u001b[39m roots = (\n\u001b[32m    115\u001b[39m     \u001b[38;5;66;03m# TODO: Should this be based on whether we\u001b[39;00m\n\u001b[32m    116\u001b[39m     \u001b[38;5;66;03m# _will_ send notifications, or only whether\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    120\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    121\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m123\u001b[39m result = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.send_request(\n\u001b[32m    124\u001b[39m     types.ClientRequest(\n\u001b[32m    125\u001b[39m         types.InitializeRequest(\n\u001b[32m    126\u001b[39m             method=\u001b[33m\"\u001b[39m\u001b[33minitialize\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    127\u001b[39m             params=types.InitializeRequestParams(\n\u001b[32m    128\u001b[39m                 protocolVersion=types.LATEST_PROTOCOL_VERSION,\n\u001b[32m    129\u001b[39m                 capabilities=types.ClientCapabilities(\n\u001b[32m    130\u001b[39m                     sampling=sampling,\n\u001b[32m    131\u001b[39m                     experimental=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    132\u001b[39m                     roots=roots,\n\u001b[32m    133\u001b[39m                 ),\n\u001b[32m    134\u001b[39m                 clientInfo=\u001b[38;5;28mself\u001b[39m._client_info,\n\u001b[32m    135\u001b[39m             ),\n\u001b[32m    136\u001b[39m         )\n\u001b[32m    137\u001b[39m     ),\n\u001b[32m    138\u001b[39m     types.InitializeResult,\n\u001b[32m    139\u001b[39m )\n\u001b[32m    141\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.protocolVersion \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m SUPPORTED_PROTOCOL_VERSIONS:\n\u001b[32m    142\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mUnsupported protocol version from the server: \u001b[39m\u001b[33m\"\u001b[39m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult.protocolVersion\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/00_projects/AI_agents/my_agents/agents_env/lib/python3.12/site-packages/mcp/shared/session.py:286\u001b[39m, in \u001b[36mBaseSession.send_request\u001b[39m\u001b[34m(self, request, result_type, request_read_timeout_seconds, metadata, progress_callback)\u001b[39m\n\u001b[32m    274\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m McpError(\n\u001b[32m    275\u001b[39m         ErrorData(\n\u001b[32m    276\u001b[39m             code=httpx.codes.REQUEST_TIMEOUT,\n\u001b[32m   (...)\u001b[39m\u001b[32m    282\u001b[39m         )\n\u001b[32m    283\u001b[39m     )\n\u001b[32m    285\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response_or_error, JSONRPCError):\n\u001b[32m--> \u001b[39m\u001b[32m286\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m McpError(response_or_error.error)\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    288\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result_type.model_validate(response_or_error.result)\n",
      "\u001b[31mMcpError\u001b[39m: Connection closed"
     ]
    }
   ],
   "source": [
    "for server in mcp_servers:\n",
    "    await server.connect()\n",
    "\n",
    "researcher_tool = await get_researcher_tool(researcher_mcp_servers)\n",
    "trader = Agent(\n",
    "    name=agent_name,\n",
    "    instructions=instructions,\n",
    "    tools=[researcher_tool],\n",
    "    mcp_servers=trader_mcp_servers,\n",
    "    model=\"gpt-4o-mini\",\n",
    ")\n",
    "with trace(agent_name):\n",
    "    result = await Runner.run(trader, prompt, max_turns=30)\n",
    "display(Markdown(result.final_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "So here we go. It has decided that it has—we gave it the tools to do it, and so it's decided to do it. It's got a bunch of different summary actions, the results of the research and the trades that were executed. It bought shares and sold shares, and that's the current portfolio status. And it's got some next steps at the bottom. So that is the result of our trader agent running using the research agent and being able to execute its tools and also being armed with the resources that we included in the prompt. And I won't be doing it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Then go and look at the trace\n",
    "\n",
    "http://platform.openai.com/traces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And let's look at the results of the trading\n",
    "\n",
    "await read_accounts_resource(agent_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now it's time to review the Python module made from this:\n",
    "\n",
    "`mcp_params.py` is where the MCP servers are specified. You'll notice I've brought in some familiar friends: memory and push notifications!\n",
    "\n",
    "`templates.py` is where the instructions and messages are set up (i.e. the System prompts and User prompts)\n",
    "\n",
    "`traders.py` brings it all together.\n",
    "\n",
    "You'll notice I've done something a bit fancy with code like this:\n",
    "\n",
    "```\n",
    "async with AsyncExitStack() as stack:\n",
    "    mcp_servers = [await stack.enter_async_context(MCPServerStdio(params)) for params in mcp_server_params]\n",
    "```\n",
    "\n",
    "This is just a tidy way to combine our \"with\" statements (known as context managers) so that we don't need to do something ugly like this:\n",
    "\n",
    "```\n",
    "async with MCPServerStdio(params=params1) as mcp_server1:\n",
    "    async with MCPServerStdio(params=params2) as mcp_server2:\n",
    "        async with MCPServerStdio(params=params3) as mcp_server3:\n",
    "            mcp_servers = [mcp_server1, mcp_server2, mcp_server3]\n",
    "```\n",
    "\n",
    "But it's equivalent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from traders import Trader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trader = Trader(\"Ed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await trader.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "await read_accounts_resource(\"Ed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now look at the trace\n",
    "\n",
    "https://platform.openai.com/traces\n",
    "\n",
    "### How many tools did we use in total?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mcp_params import trader_mcp_server_params, researcher_mcp_server_params\n",
    "\n",
    "all_params = trader_mcp_server_params + researcher_mcp_server_params(\"ed\")\n",
    "\n",
    "count = 0\n",
    "for each_params in all_params:\n",
    "    async with MCPServerStdio(params=each_params, client_session_timeout_seconds=60) as server:\n",
    "        mcp_tools = await server.list_tools()\n",
    "        count += len(mcp_tools)\n",
    "print(f\"We have {len(all_params)} MCP servers, and {count} tools\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
