{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome back to Python Notebooks!\n",
    "\n",
    "Didja miss me??\n",
    "\n",
    "### And welcome to Week 4, Day 2 - introducing LangGraph!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image, display\n",
    "import gradio as gr\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some useful constants\n",
    "\n",
    "nouns = [\"Cabbages\", \"Unicorns\", \"Toasters\", \"Penguins\", \"Bananas\", \"Zombies\", \"Rainbows\", \"Eels\", \"Pickles\", \"Muffins\"]\n",
    "adjectives = [\"outrageous\", \"smelly\", \"pedantic\", \"existential\", \"moody\", \"sparkly\", \"untrustworthy\", \"sarcastic\", \"squishy\", \"haunted\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our favorite first step! Crew was doing this for us, by the way.\n",
    "load_dotenv(override=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now I need to explain something called annotated. So hopefully you're somewhat familiar with things called type hints in Python, an optional feature that is often used in engineering. To give you an example, supposing that we have a Python function called shout that takes some text, and the job of shout is to print the text in uppercase. That seems fairly simple, and let's just shout hello like that, hopefully no surprise, hello in capitals comes up. Well the type hints is when you are clear to Python what is the type of variable you're using at each point. So you can say that that text is a string by putting colon strut, and you can put here that will return a string, or it's not returning anything, it's returning none, but if we also have it, if we leave it like this, we have it be returning a string, then it will be unhappy, but we would need to then also return text.upper as well, and then it will run. So these are called type hints, and they are a useful way of specifying what's going on. There is a feature that you can use called annotated, in which we could type annotated string comma, and then we can put some message here, something to be shouted. And this is something, I need to close the square brackets, this is just extra information that's a sort of FYI that's included in here. Python doesn't make any use of this at all, but if we are going to provide this function to another platform or in some other context, someone might want to read how we've annotated it, and that might be useful for someone. So annotations can be used for this purpose of kind of tagging variables to have a purpose. So this should run without any change at all, that is completely ignored, and it's just a useful way of adding some extra information in case it matters to somebody else. And it is going to matter to somebody else, LandGraph is going to want us to annotate in order to tell it something. Let's come on to that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HELLO\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'HELLO'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def shout(text: Annotated[str, \"something to be shouted\"]) -> str:\n",
    "    print(text.upper())\n",
    "    return text.upper()\n",
    "\n",
    "shout(\"hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A word about \"Annotated\"\n",
    "\n",
    "You probably know this; type hinting is a feature in Python that lets you specify the type of something:\n",
    "\n",
    "`my_favorite_things: List`\n",
    "\n",
    "But you may not know this:\n",
    "\n",
    "You can also use something called \"Annotated\" to add extra information that somebody else might find useful:\n",
    "\n",
    "`my_favorite_things: Annotated[List, \"these are a few of mine\"]`\n",
    "\n",
    "LangGraph needs us to use this feature when we define our State object.\n",
    "\n",
    "It wants us to tell it what function it should call to update the State with a new value.\n",
    "\n",
    "This function is called a **reducer**.\n",
    "\n",
    "LangGraph provides a default reducer called `add_messages` which takes care of the most common case.\n",
    "\n",
    "And that hopefully explains why the State looks like this.\n",
    "\n",
    "---\n",
    "So I explained here again, you could have a variable like my favorite things that could be a list, and you could say that my favorite things, you could actually not just describe it as a list, but say that it is annotated, it's a list, and these are a few of mine added as an annotation to my favorite things. So why do I tell you this? Well, it all comes back to these things called reducers. We are about to define our state object, and when we do so, we're going to give it a few fields. We have to give them a type, and when we give them a type, we don't just specify the type, but we use annotated to be able to specify a reducer if LandGraph is expected to use a reducer. That is the technique, you use annotated to do that, and that is what we're going to do. And as it happens, LandGraph comes with one out of the box that's very useful for us called add messages, and that is one that I just imported up here. So if you look up here, one of my imports was from LandGraph.graph.message import add messages. So that is, it's like a function, and it's a function that you can annotate with if you want to say, hey, this is the reducer I'd like you to use. So to make this feel real, let's go ahead and define our state. So you remember step one in the puzzle is to define the state object. That is what we're doing here. We are going to have a state object. Now, state objects, you can define them in many ways. They can in fact be any Python object that you want. It's most common to either have it be a Pydantic object that we met in the last week, it can be, or we met in the last two weeks, it can be a Pydantic object, meaning it's a subclass of base model. It can also be something called a typed dict, which is a particular type of dictionary in Python where you specify what the keys need to be, but it can also be anything. But it is quite common to use either Pydantic objects or typed dicts, and we will use Pydantic since that's something that we're familiar with. So we are going to have a state object defining the state of our system, and it only has one field, and that's called messages. And that is going to store in it a list of messages. And this list of messages is going to be passed around our graph, and over time it's going to build up as messages get added to it. And so we are going to say that it's something that's annotated, it is a list. So it consists of a list of things, of messages, and we are going to then, because we're annotating it, we can provide an annotation that's ignored by Python, but it can be used by Landron. And that annotation is where we get to specify the reducer, the function that will be called in order to combine one state with another. And we're going to use one out of the box called addMessages. It is a reducer that is used to add messages, and it's very simple, it's very vanilla. All it does is it assumes this is a list, and if you return something with an item to the list, it just combines it with everything else in the list before. It concatenates these lists together. That's all it does. So hopefully that makes a bit of sense. If not, then you'll see, it'll become clear as we use this exactly what's going on and why the use of this and the reducer and how it's working.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Define the State object\n",
    "\n",
    "You can use any python object; but it's most common to use a TypedDict or a Pydantic BaseModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class State(BaseModel):\n",
    "    messages: Annotated[list, add_messages]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So step one, we define the state object. Step two, we start the graph builder, and that is just a matter of calling this thing called stateGraph, instantiating a stateGraph, passing in state. And one thing to get your head around here is that what I'm passing in there, the thing I just highlighted, it's not an object, I'm not instantiating, I'm not creating a state and passing that in with messages and so on. No, I'm passing in the class. I'm passing in the type of thing that represents our state. That is what I'm using to create my stateGraph, and this is beginning the graph building process. This is part of the five steps before we actually run our agentic framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Start the Graph Builder with this State class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Create a Node\n",
    "\n",
    "A node can be any python function.\n",
    "\n",
    "The reducer that we set before gets automatically called to combine this response with previous responses\n",
    "\n",
    "---\n",
    "Remember, a node is a function. So we're going to create a function. It's called our_first_node. It takes an old state and it returns a new state. And states are immutable, as we say, and so we are not going to do anything. We're not going to come and mutate the old state. In fact, you may see from the way that it's grayed out here that we don't actually touch old state, which is unusual, but just for this example. So what are we actually going to do? So we're going to make a string called reply, and that reply is going to be some random word choice of a noun, and then the word are, and then a random choice of an adjective. And we're going to create one of these kinds of message structures, an OpenAI familiar message structure, and put that into messages. We're going to say that the new state is another new state class. We're going to instantiate it, passing in these messages, and we are going to return that, the new state. And that is the end of our first node. And we then call graphBuilder.addNode. This is how we officially add it to the graph that is being built. We give it a name. We call it our_first_node, and we pass in the function, the function that represents the node called our_first_node.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10bb8a4e0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def our_first_node(old_state: State) -> State:\n",
    "\n",
    "    reply = f\"{random.choice(nouns)} are {random.choice(adjectives)}\"\n",
    "    messages = [{\"role\": \"assistant\", \"content\": reply}]\n",
    "\n",
    "    new_state = State(messages=messages)\n",
    "\n",
    "    return new_state\n",
    "\n",
    "graph_builder.add_node(\"first_node\", our_first_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Create Edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10bb8a4e0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_builder.add_edge(START, \"first_node\")\n",
    "graph_builder.add_edge(\"first_node\", END)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and now we're coming on to look at creating our edges. So you can see here that I now call graphBuilder.add_edge to add a couple of edges, and you'll see that these words start and end there. So what are they? Well, these are things that we've imported at the top from landgraph.graph. They are constants, start and end, and of course they signify the beginning of our workflow and the end of it. And so here what we say is we want an edge to take us from the start to our first node, and then we want another edge to go from the first node to the end. Okay, that sounds logical, doesn't it? So we'll run that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Compile the Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now with that we get to step five, which you'll remember is compiling the graph and saying we're done, this is our workflow. And we can now display it. This is rather nice. A quick way to show visually what it is we're talking about. And hopefully this will be no surprise. We've got a start going into our first node, a first node going into our end. What could be easier? That's lovely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That's it! Showtime!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so we've done the five steps, which is, of course, the first part of running a landgraph system. We've compiled our graph, and we've done it by adding nodes and edges. It's now time to run it. \n",
    "\n",
    "Okay, and what we're going to do is to run it, we're going to create a gradio chat function. Why not? Remember, gradio chat functions take the user's current input and the history of prior inputs, and it's meant to respond with the next output. That's just what you do with a gradio chat function that we're going to pass into gradio's chat interface right there. So that's what we have to do. So what do we want to do? Well, we're going to turn the message into a standard OpenAI format and put that into a message. We're then going to create a state object with that as the message. We are then going to invoke our graph, and this is a key lang chain word, invoke. You may be familiar. Sorry, I said lang chain. It's the landgraph word, invoke, but you may be familiar with it because it's the word in lang chain as well. So you invoke a graph in landgraph with the state in order to get the result. So it's going to execute our graph, and what will come out will be the result, and we will print it, and we will also return it, and that will come out of our chat function. And so with that, let's run this and see what happens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='Hi there!', additional_kwargs={}, response_metadata={}, id='f76cca37-c987-472f-9620-c288bd77cdaf'), AIMessage(content='Muffins are pedantic', additional_kwargs={}, response_metadata={}, id='1cd4ca71-578f-4f45-a67e-3c949cc1a5dd')]}\n",
      "{'messages': [HumanMessage(content='How?', additional_kwargs={}, response_metadata={}, id='f316c9b7-be6f-46d8-b609-62d68e06a987'), AIMessage(content='Toasters are untrustworthy', additional_kwargs={}, response_metadata={}, id='3e38c470-d898-4fdb-9ff8-aa4ba56e39d2')]}\n",
      "{'messages': [HumanMessage(content='My name is Alex', additional_kwargs={}, response_metadata={}, id='dd96f73a-f075-4af1-80c9-ea0556cb38c5'), AIMessage(content='Zombies are pedantic', additional_kwargs={}, response_metadata={}, id='3506f2f8-0a0d-403e-8867-52f90b43f380')]}\n"
     ]
    }
   ],
   "source": [
    "def chat(user_input: str, history):\n",
    "    message = {\"role\": \"user\", \"content\": user_input}\n",
    "    messages = [message]\n",
    "    state = State(messages=messages)\n",
    "    result = graph.invoke(state)\n",
    "    print(result)\n",
    "    return result[\"messages\"][-1].content\n",
    "\n",
    "\n",
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, we have a gradio UI. That's good. That's a highlight. `Muffins are haunted`. Is that so? `Penguins are sparkly`. You don't say. `Penguins are outrageous`. For real. `Pickles are untrustworthy`. You get the idea. So this is the result of our small language model that is picking a random noun and adjective, and I show you this if you're wondering, what on earth are you doing? I'm doing it to show that the landgraph setup has nothing to do with LLMs necessarily. The node is just a function. In this case, a silly function, but it's a function there, and it's taking in a state, and it's returning a state, and it doesn't need to have anything to do with LLMs. Now, down here, I'm printing the result of this, and let me show you that print statement. We're printing what's coming back from calling invoke on the graph, and I want to point out that it may be something a bit different to what you're expecting because it's not messages with just a list of strings. It's got a list of these things called human message, which you may know from language chain work. It's like a construct to package things up, and this is, of course, the result of the reducer running, and when I said before that the reducer simply concatenates things into a list, I wasn't telling the full story because it also does some of this packaging up that comes with landgraphs, so if it just takes the text that's come back, it knows how to package it into a human message in terms of the things that I was saying and an AI message in terms of muffins are haunted and penguins are sparkly and the like. So this is some of the stuff happening behind the scenes as a result of landgraph, which doesn't really matter to us. We're taking advantage of that, but we just wrote a simple, a super simple state, a super simple node. We made a state that contained messages. We made a node. We take in an old state. We return a new state, which is using this random sentence, and it works. We can invoke our graph and get a response, and we can have a conversation, a rather one-sided conversation with a silly language model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But why did I show you that?\n",
    "\n",
    "To make the point that LangGraph is all about python functions - it doesn't need to involve LLMs!!\n",
    "\n",
    "Now it's on to a proper example that we'll use with LandGraph. To state the obvious, the reason I showed you the silly example was because I wanted to show that nodes don't need to have calls to LLMs and they still do what they're meant to do. But now we are going to add an LLM.\n",
    "\n",
    "So we start by defining a state, we create a graph builder with that state...\n",
    "\n",
    "Now we'll do the 5 steps again, but in 1 shot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define the State object\n",
    "class State(BaseModel):\n",
    "    messages: Annotated[list, add_messages]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Start the Graph Builder with this State class\n",
    "graph_builder = StateGraph(State)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and now we create a LLM, a real LLM, using ChatOpenAI. So ChatOpenAI is a construct from LangChain, the sibling to LandGraph, and that's what we'll be using to connect with our LLM. And now, you don't need to use LangChain's LLMs for this. You can use any LLMs, you can directly call the LLM yourself, you could also use maybe OpenAI Agents SDK, but it does make things a bit simpler sometimes if you use LangChain and most of the community examples, of course, go from LandGraph to LangChain. So it's easy to do it that way and that's what we'll do for here.\n",
    "\n",
    "So we're going to create a new node called ChatBotNode. It takes an old state and it returns a new state. And what does it do? Well, it takes the LLM and it invokes on that LLM, so it's again the LangChain-LandGraph word invoke, passing in the messages from old state. So old state has a messages field and that is what we pass in. And then for the new state, it creates a new state object, which contains within it, as in its messages field, it contains the response, and we return the new state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10b6f26f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Create a Node\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "def chatbot_node(old_state: State) -> State:\n",
    "    response = llm.invoke(old_state.messages)\n",
    "    new_state = State(messages=[response])\n",
    "    return new_state\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we add that node called ChatBot into our graph builder, done.\n",
    "Now we'll add some edges from start to ChatBot, from ChatBot to end, done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x10b6f26f0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Create Edges\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", END)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now we will compile our graph, step five, and we'll look at the graph and sure enough, it goes start to ChatBot to end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Step 5: Compile the Graph\n",
    "graph = graph_builder.compile()\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then we put it all together in a simple Gradio chat function.\n",
    "It takes an initial state, which is a state object, set up with these messages like so.\n",
    "We then call graph.invoke to actually call our graph.\n",
    "We print the result and we will also show the result back in Gradio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That's it! And, let's do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='Hi there!', additional_kwargs={}, response_metadata={}, id='12532b7e-c3a3-4220-a944-18d5fda16e00'), AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 10, 'total_tokens': 19, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': None, 'id': 'chatcmpl-Bw2Z3axf4dYFstgUC7Pu11IaY6Ku9', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--21fdcac8-df4e-4c70-a9db-76154176c69d-0', usage_metadata={'input_tokens': 10, 'output_tokens': 9, 'total_tokens': 19, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
      "{'messages': [HumanMessage(content='I´m Alex Just ', additional_kwargs={}, response_metadata={}, id='0e80f2b0-5e46-408a-ad80-d9d7a6a0b86c'), AIMessage(content='Hi, Alex! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 13, 'total_tokens': 24, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': None, 'id': 'chatcmpl-Bw2ZHXi1DslyyEInQuOrKZnVe6Aig', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--4503b1c1-61a0-45b3-b066-4c067121568e-0', usage_metadata={'input_tokens': 13, 'output_tokens': 11, 'total_tokens': 24, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n",
      "{'messages': [HumanMessage(content='What´s my name?', additional_kwargs={}, response_metadata={}, id='22e3e1d7-792b-4502-837f-cbc3674eff24'), AIMessage(content=\"I'm sorry, but I don't know your name. How can I assist you today?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 12, 'total_tokens': 29, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': None, 'id': 'chatcmpl-Bw2a64vIF99tzEGbjyEUvEeBq5HKh', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='run--f69625a6-85c0-4f11-93db-14ffd65cd8e0-0', usage_metadata={'input_tokens': 12, 'output_tokens': 17, 'total_tokens': 29, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}\n"
     ]
    }
   ],
   "source": [
    "def chat(user_input: str, history):\n",
    "    initial_state = State(messages=[{\"role\": \"user\", \"content\": user_input}])\n",
    "    result = graph.invoke(initial_state)\n",
    "    print(result)\n",
    "    return result['messages'][-1].content\n",
    "\n",
    "\n",
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here it is, and I can say hi there. And it's actually calling OpenAI now, it's not using our silly adjectives.\n",
    "And you'll see down here that there's the user message and the response coming in these objects, this human message object that is coming back.\n",
    "Sorry, the human message is my hi there. I mean, there should be an AI message. There is.\n",
    "There is the AI message, which is the response actually coming from OpenAI.\n",
    "\n",
    "The one thing that's worth noting is that if I continue this conversation, every time we are invoking this graph, and you will see what you have probably already suspected, which is that we're not actually keeping track of any history here. Let's see that in action.\n",
    "\n",
    "If I say, my name's Ed.\n",
    "\n",
    ">\"Nice to meet you, Ed. How can I assist you today?\"  \n",
    ">Then I say: What's my name?  \n",
    ">\"I'm sorry. I don't have access to your personal data.\"  \n",
    "\n",
    "So there's a sign that it's not able to keep context, and you can see it yourself if you read the information that's going to and fro.\n",
    "\n",
    "Because we've just got this simple graph that we were invoking each time, there's nothing particularly interesting happening here, and the state just doesn't contain a history or anything.\n",
    "\n",
    "So that's one of the things that we clearly need to address, and the good news is that we will indeed address it, but the bad news is not until tomorrow.\n",
    "But we'll also address things like tools, our old favorite, along with a couple of other things.\n",
    "\n",
    "So look forward to it. I'll see you then."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agents_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
